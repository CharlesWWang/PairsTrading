{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A benchmark Pairs Trading strategy \n",
    "\n",
    "This notebook explores a pairs trading strategy using bollinger bands. This projected is being developed as part of a master thesis for the degree of Electrical and Computer Engineering.\n",
    "\n",
    "**Author:** Sim√£o Moraes Sarmento <br /> \n",
    "**Contact:** simaosarmento@hotmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "This notebook requires code from:\n",
    "\n",
    "Python files:\n",
    "- `class_SeriesAnalyser.py` - contains a set of functions to deal with time series analysis.\n",
    "- `class_Trader.py` - contains a set of functions concerning trading strategies.\n",
    "- `class_DataProcessor.py` - contains a set of functions concerning the data pre processing.\n",
    "\n",
    "Pickle files:\n",
    "- pickle file containing pairs to be traded (obtained from running `PairsTrading_CommodityETFs-Clustering.ipynb`)\n",
    "\n",
    "As a good practise, the notebook solely intends to exemplify the application of different trading strategies for different dataset examples, rather than coding the strategies theirselves. Please look into the files menitoned above for more detailed info on how the functions are built."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import json\n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import coint, adfuller\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Import Datetime and the Pandas DataReader\n",
    "from datetime import datetime\n",
    "from pandas_datareader import data, wb\n",
    "\n",
    "# Import alpha vantage\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "\n",
    "# Import scikit instruments\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# just set the seed for the random number generator\n",
    "np.random.seed(107)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = 'config/config_commodities_2010_2019.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_file, 'r') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config['dataset']['ticker_segment_dict'], 'rb') as handle:\n",
    "    ticker_segment_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%aimport class_SeriesAnalyser, class_Trader, class_DataProcessor\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_analyser = class_SeriesAnalyser.SeriesAnalyser()\n",
    "trader = class_Trader.Trader()\n",
    "data_processor = class_DataProcessor.DataProcessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve prices data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by retrieving the data from a Dataframe saved in a pickle file, as it was previously processed in the `PairsTrading_CommodityETFS_Datapreprocessing.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intraday\n",
    "df_prices = pd.read_pickle('data/etfs/pickle/commodity_ETFs_from_2014_complete.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 116 tickers\n",
      "Total of 105 tickers after removing tickers with Nan values\n"
     ]
    }
   ],
   "source": [
    "# split data in training and test\n",
    "df_prices_train, df_prices_test = data_processor.split_data(df_prices,\n",
    "                                                            ('01-01-2013',\n",
    "                                                             '31-12-2015'),\n",
    "                                                            ('01-01-2016',\n",
    "                                                             '31-12-2016'),\n",
    "                                                            remove_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78222"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_prices_train)+len(df_prices_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intra day\n",
    "#with open('data/etfs/pickle/pairs_unfiltered_intraday.pickle', 'rb') as handle:\n",
    "#    pairs = pickle.load(handle)\n",
    "\n",
    "#with open('data/etfs/pickle/pairs_category_intraday.pickle', 'rb') as handle:\n",
    "#with open('data/etfs/pickle/2013-2017/pairs_category_intraday.pickle', 'rb') as handle:\n",
    "#    pairs = pickle.load(handle)\n",
    "\n",
    "with open('data/etfs/pickle/2013-2017/pairs_unsupervised_learning_intraday.pickle', 'rb') as handle:\n",
    "    pairs = pickle.load(handle)\n",
    "    \n",
    "# interday  \n",
    "#with open('data/etfs/pickle/pairs_unfiltered_interday.pickle', 'rb') as handle:\n",
    "#    pairs = pickle.load(handle)\n",
    "\n",
    "#with open('data/etfs/pickle/pairs_category_interday.pickle', 'rb') as handle:\n",
    "#    pairs = pickle.load(handle)\n",
    "\n",
    "#with open('data/etfs/pickle/pairs_unsupervised_learning_interday.pickle', 'rb') as handle:\n",
    "#    pairs = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### lookback_multiplier= config['trading']['lookback_multiplier']\n",
    "entry_multiplier= config['trading']['entry_multiplier']\n",
    "exit_multiplier= config['trading']['exit_multiplier']\n",
    "# obtain trading filter info\n",
    "if config['trading_filter']['active'] == 1:\n",
    "    trading_filter = config['trading_filter']\n",
    "else:\n",
    "    trading_filter = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply trading strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying the fixed beta strategy in validation period**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_split = '2015-01-01'\n",
    "\n",
    "# intraday\n",
    "n_years_val = round(len(df_prices_train[train_val_split:])/(240*78))\n",
    "\n",
    "# interday\n",
    "#n_years_val = round(len(df_prices_train)/(240))\n",
    "\n",
    "n_years_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair: 70/70"
     ]
    }
   ],
   "source": [
    "entry_multiplier= config['trading']['entry_multiplier']\n",
    "exit_multiplier= config['trading']['exit_multiplier']\n",
    "train_results_without_costs, train_results_with_costs, performance_threshold_train = \\\n",
    "        trader.apply_threshold_strategy(pairs, \n",
    "                                        2,#entry_multiplier,\n",
    "                                        0,#exit_multiplier,\n",
    "                                        trading_filter,\n",
    "                                        test_mode=False,\n",
    "                                        rebalance=False,\n",
    "                                        train_val_split=train_val_split\n",
    "                                       )\n",
    "\n",
    "sharpe_results_threshold_train_nocosts, cum_returns_threshold_train_nocosts = train_results_without_costs\n",
    "sharpe_results_threshold_train_w_costs, cum_returns_threshold_train_w_costs = train_results_with_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average result:  0.855358804596568\n",
      "avg_annual_roi:  19.33984262534323\n",
      "90.0 % of the pairs had positive returns\n"
     ]
    }
   ],
   "source": [
    "# WARNING: MUST CHANGE SHARPE RATIO\n",
    "avg_sharpe_train, total_roi_train, anual_roi_train, positive_pct_train = \\\n",
    "    trader.calculate_metrics(sharpe_results_threshold_train_w_costs, cum_returns_threshold_train_w_costs,\n",
    "                             n_years_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio Distribution: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1113e1f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Sharpe Ratio Distribution: ')\n",
    "n, bins, patches = plt.hist(sharpe_results_threshold_train_w_costs, bins = 16, normed=True, orientation='vertical',\n",
    "                            color='red', rwidth=0.9, align='mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cum_returns_threshold_train_w_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.29941912, 0.42898667, 0.37903297, 3.53850409, 0.72055073,\n",
       "       1.15029723, 1.27496551, 0.48397309, 1.26041092, 0.43324688,\n",
       "       0.39861761, 0.32241468, 0.3919097 , 0.28125813, 0.44891968,\n",
       "       0.47145884, 0.20592696, 1.15981989, 0.77402251, 2.91923373,\n",
       "       0.27189443, 0.39106753, 0.64547281, 0.36103208, 0.22407491,\n",
       "       0.56946381, 1.03992335, 0.30150536, 0.62524962, 0.64650497,\n",
       "       0.29254041, 1.20367172, 0.43240833, 0.536094  , 0.60027222,\n",
       "       0.568508  , 0.22617437, 1.0131795 , 1.26270533, 0.49561819,\n",
       "       0.45618743, 0.46013209, 0.17507272, 0.23624969, 0.89313868,\n",
       "       0.27433744, 0.10819655, 0.71946346, 0.27850556, 0.14389114,\n",
       "       0.35301363, 2.57319027, 0.16416949, 3.61108122, 0.24711413,\n",
       "       0.11514169, 0.89385653, 1.61352922, 0.46411229, 0.40592932,\n",
       "       5.93564081, 1.65492272, 1.86916972, 0.71101711, 6.70769207,\n",
       "       0.5186711 , 0.19435762, 0.58001294, 0.49274303, 0.22520509])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas = list()\n",
    "for i in range(len(pairs)):\n",
    "    betas.append(pairs[i][2]['coint_coef'])\n",
    "np.asarray(betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average result:  0.8552927754046352\n",
      "avg_annual_roi:  19.336094583957596\n",
      "90.14084507042253 % of the pairs had positive returns\n"
     ]
    }
   ],
   "source": [
    "results_training, pairs_summary_training = trader.summarize_results(sharpe_results_threshold_train_w_costs,\n",
    "                                                                    cum_returns_threshold_train_w_costs,\n",
    "                                                                    performance_threshold_train,\n",
    "                                                                    pairs,\n",
    "                                                                    ticker_segment_dict, n_years_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out of Sample Analysis\n",
    "\n",
    "In this section, we analyze the performance of the strategy in the validation dataset. \n",
    "\n",
    "We proceed with some data exploration analysis. For this purpose we will do the following:\n",
    "\n",
    "- Analyze which percentage of the identified pairs are still cointegrated in the validation period.\n",
    "- Analyze which percentage of pairs have positive returns, and how many of those are still cointegrated.\n",
    "- Analyze how many new pais were not identified to be cointegrated up to the validation period.\n",
    "- Run strategy for identified pairs in training period.\n",
    "\n",
    "This analysis will help us getting some insight into how the cointegrated pairs vary from time to time, and therefore how we should allocate our resources to predict when pairs are not cointegrated anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the Strategy out-of Sample\n",
    "\n",
    "We might want to apply the strategy in all pairs identified. Or, instead, we might prefer to apply the strategy only on those pairs that turned out to be profitable. Let's compare how both approaches work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intraday\n",
    "n_years_test = round(len(df_prices_test)/(240*78))\n",
    "\n",
    "# interday\n",
    "#n_years_test = round(len(df_prices_test)/(240))\n",
    "\n",
    "n_years_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1: Unrestricted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic Threshold Strategy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair: 70/70"
     ]
    }
   ],
   "source": [
    "results_without_costs, results_with_costs, performance_threshold_test = trader.apply_threshold_strategy(pairs, \n",
    "                                                                                             2,\n",
    "                                                                                             0,\n",
    "                                                                                             trading_filter,\n",
    "                                                                                             test_mode=True,\n",
    "                                                                                             rebalance=False)\n",
    "sharpe_results_threshold_test_nocosts, cum_returns_threshold_test_nocosts = results_without_costs\n",
    "sharpe_results_threshold_test_w_costs, cum_returns_threshold_test_w_costs = results_with_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average result:  0.9475003484029028\n",
      "avg_annual_roi:  26.452216922141126\n",
      "78.57142857142857 % of the pairs had positive returns\n"
     ]
    }
   ],
   "source": [
    "_, _, _, _ = trader.calculate_metrics(sharpe_results_threshold_test_w_costs, cum_returns_threshold_test_w_costs,\n",
    "                                      n_years_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: Keeping only pairs that had positive returns in the training period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_returns_threshold_train_w_costs = np.asarray(cum_returns_threshold_train_w_costs)\n",
    "profitable_pairs_indices = np.argwhere(cum_returns_threshold_train_w_costs > 0)\n",
    "profitable_pairs = [pairs[i] for i in profitable_pairs_indices.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair: 63/63"
     ]
    }
   ],
   "source": [
    "results_without_costs, results_with_costs, performance_threshold_test = trader.apply_threshold_strategy(\n",
    "                                                                                    profitable_pairs, \n",
    "                                                                                    2,#entry_multiplier,\n",
    "                                                                                    0,#exit_multiplier,\n",
    "                                                                                    trading_filter,\n",
    "                                                                                    test_mode=True,\n",
    "                                                                                    rebalance=False)\n",
    "sharpe_results_threshold_test_nocosts, cum_returns_threshold_test_nocosts = results_without_costs\n",
    "sharpe_results_threshold_test_w_costs, cum_returns_threshold_test_w_costs = results_with_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average result:  0.9203844261192017\n",
      "avg_annual_roi:  26.8974808798756\n",
      "76.19047619047619 % of the pairs had positive returns\n"
     ]
    }
   ],
   "source": [
    "_, _, _, _ = trader.calculate_metrics(sharpe_results_threshold_test_w_costs, cum_returns_threshold_test_w_costs,\n",
    "                                      n_years_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 3: Keeping only top 10 pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpe_results_threshold_train_w_costs = np.asarray(sharpe_results_threshold_train_w_costs)\n",
    "sorted_pairs_indices = np.argsort(sharpe_results_threshold_train_w_costs)[::-1][:10]\n",
    "top_10_pairs = [pairs[i] for i in sorted_pairs_indices.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting by returns seems to give better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair: 10/10"
     ]
    }
   ],
   "source": [
    "results_without_costs, results_with_costs, performance_threshold_test = trader.apply_threshold_strategy(\n",
    "                                                                                    top_10_pairs, \n",
    "                                                                                    2,#entry_multiplier,\n",
    "                                                                                    0,#exit_multiplier,\n",
    "                                                                                    trading_filter,\n",
    "                                                                                    test_mode=True,\n",
    "                                                                                    rebalance=False)\n",
    "sharpe_results_threshold_test_nocosts, cum_returns_threshold_test_nocosts = results_without_costs\n",
    "sharpe_results_threshold_test_w_costs, cum_returns_threshold_test_w_costs = results_with_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average result:  0.9039469736045449\n",
      "avg_annual_roi:  23.85271754722924\n",
      "90.0 % of the pairs had positive returns\n"
     ]
    }
   ],
   "source": [
    "_, _, _, _ = trader.calculate_metrics(sharpe_results_threshold_test_w_costs, cum_returns_threshold_test_w_costs,\n",
    "                                      n_years_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_returns_threshold_train_w_costs = np.asarray(cum_returns_threshold_train_w_costs)\n",
    "sorted_pairs_indices = np.argsort(cum_returns_threshold_train_w_costs)[::-1][:10]\n",
    "top_10_pairs = [pairs[i] for i in sorted_pairs_indices.flatten()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average result:  1.9145168927950444\n",
      "avg_annual_roi:  21.21488842121981\n",
      "100.0 % of the pairs had positive returns\n"
     ]
    }
   ],
   "source": [
    "results, pairs_summary = trader.summarize_results(sharpe_results_threshold_test_w_costs,\n",
    "                                                  cum_returns_threshold_test_w_costs,\n",
    "                                                  performance_threshold_test,\n",
    "                                                  profitable_pairs, ticker_segment_dict,\n",
    "                                                  n_years_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Leg1</th>\n",
       "      <th>Leg1_Segmt</th>\n",
       "      <th>Leg2</th>\n",
       "      <th>Leg2_Segmt</th>\n",
       "      <th>t_statistic</th>\n",
       "      <th>p_value</th>\n",
       "      <th>zero_cross</th>\n",
       "      <th>half_life</th>\n",
       "      <th>hurst_exponent</th>\n",
       "      <th>positive_trades</th>\n",
       "      <th>negative_trades</th>\n",
       "      <th>sharpe_result</th>\n",
       "      <th>positive_trades_per_pair_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DGP</td>\n",
       "      <td>Leveraged Commodities: Precious Metals Gold</td>\n",
       "      <td>UGL</td>\n",
       "      <td>Leveraged Commodities: Precious Metals Gold</td>\n",
       "      <td>-3.397245</td>\n",
       "      <td>0.011053</td>\n",
       "      <td>8623</td>\n",
       "      <td>139</td>\n",
       "      <td>0.247655</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>4.904072</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DBA</td>\n",
       "      <td>Commodities: Agriculture</td>\n",
       "      <td>RJZ</td>\n",
       "      <td>Commodities: Broad Market Metals</td>\n",
       "      <td>-3.269818</td>\n",
       "      <td>0.016283</td>\n",
       "      <td>453</td>\n",
       "      <td>3146</td>\n",
       "      <td>0.397512</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.039132</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DZZ</td>\n",
       "      <td>Inverse Commodities: Precious Metals Gold</td>\n",
       "      <td>GLL</td>\n",
       "      <td>Inverse Commodities: Precious Metals Gold</td>\n",
       "      <td>-4.209984</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>1731</td>\n",
       "      <td>264</td>\n",
       "      <td>0.191601</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.751853</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GCC</td>\n",
       "      <td>Commodities: Broad Market</td>\n",
       "      <td>RJA</td>\n",
       "      <td>Commodities: Agriculture</td>\n",
       "      <td>-3.292388</td>\n",
       "      <td>0.015222</td>\n",
       "      <td>1751</td>\n",
       "      <td>1106</td>\n",
       "      <td>0.360744</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.504868</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PXE</td>\n",
       "      <td>Equity: U.S. Oil &amp; Gas Exploration &amp; Production</td>\n",
       "      <td>PXI</td>\n",
       "      <td>Equity: U.S. Energy</td>\n",
       "      <td>-3.254852</td>\n",
       "      <td>0.017021</td>\n",
       "      <td>1374</td>\n",
       "      <td>462</td>\n",
       "      <td>0.231966</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.180221</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DBE</td>\n",
       "      <td>Commodities: Energy</td>\n",
       "      <td>GSP</td>\n",
       "      <td>Commodities: Broad Market</td>\n",
       "      <td>-2.864635</td>\n",
       "      <td>0.049618</td>\n",
       "      <td>1721</td>\n",
       "      <td>406</td>\n",
       "      <td>0.174335</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.024143</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RJA</td>\n",
       "      <td>Commodities: Agriculture</td>\n",
       "      <td>RJZ</td>\n",
       "      <td>Commodities: Broad Market Metals</td>\n",
       "      <td>-3.566577</td>\n",
       "      <td>0.006433</td>\n",
       "      <td>491</td>\n",
       "      <td>2149</td>\n",
       "      <td>0.388688</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997330</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Leg1                                       Leg1_Segmt Leg2  \\\n",
       "0  DGP      Leveraged Commodities: Precious Metals Gold  UGL   \n",
       "1  DBA                         Commodities: Agriculture  RJZ   \n",
       "2  DZZ        Inverse Commodities: Precious Metals Gold  GLL   \n",
       "3  GCC                        Commodities: Broad Market  RJA   \n",
       "4  PXE  Equity: U.S. Oil & Gas Exploration & Production  PXI   \n",
       "5  DBE                              Commodities: Energy  GSP   \n",
       "6  RJA                         Commodities: Agriculture  RJZ   \n",
       "\n",
       "                                    Leg2_Segmt  t_statistic   p_value  \\\n",
       "0  Leveraged Commodities: Precious Metals Gold    -3.397245  0.011053   \n",
       "1             Commodities: Broad Market Metals    -3.269818  0.016283   \n",
       "2    Inverse Commodities: Precious Metals Gold    -4.209984  0.000634   \n",
       "3                     Commodities: Agriculture    -3.292388  0.015222   \n",
       "4                          Equity: U.S. Energy    -3.254852  0.017021   \n",
       "5                    Commodities: Broad Market    -2.864635  0.049618   \n",
       "6             Commodities: Broad Market Metals    -3.566577  0.006433   \n",
       "\n",
       "   zero_cross  half_life  hurst_exponent  positive_trades  negative_trades  \\\n",
       "0        8623        139        0.247655              143                0   \n",
       "1         453       3146        0.397512                3                0   \n",
       "2        1731        264        0.191601                3                0   \n",
       "3        1751       1106        0.360744                2                0   \n",
       "4        1374        462        0.231966                1                0   \n",
       "5        1721        406        0.174335                1                0   \n",
       "6         491       2149        0.388688                1                0   \n",
       "\n",
       "   sharpe_result  positive_trades_per_pair_pct  \n",
       "0       4.904072                         100.0  \n",
       "1       2.039132                         100.0  \n",
       "2       1.751853                         100.0  \n",
       "3       1.504868                         100.0  \n",
       "4       1.180221                         100.0  \n",
       "5       1.024143                         100.0  \n",
       "6       0.997330                         100.0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Pairs' Overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There could be two possible interpretations for pairs' overlap.\n",
    "1. We might be interested in checking which of the cointegrated pairs found in the training dataset are also cointegrated in the test set; Furthermore we want to explore how the two types of pairs perform.\n",
    "2. We might be interested in finding if the pairs that would have been found in the test set by performing PCA + clustering would be cointegrated in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with **1)**, let's see how many of the identified pairs actually turned out to be cointegrated during this period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_overlapped, pairs_overlapped_index = series_analyser.pairs_overlap(pairs,\n",
    "                                  config['pair_restrictions']['p_value_threshold'],\n",
    "                                  config['pair_restrictions']['min_zero_crossings'],\n",
    "                                  config['pair_restrictions']['min_half_life'],\n",
    "                                  config['pair_restrictions']['hurst_threshold'])\n",
    "print('{} of the {} pairs identified in the training set are also cointegrated in the test set'.format(\\\n",
    "    len(pairs_overlapped), len(pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profitable_pairs_overlapped, profitable_pairs_overlapped_index = series_analyser.pairs_overlap(profitable_pairs,\n",
    "                                  config['pair_restrictions']['p_value_threshold'],\n",
    "                                  config['pair_restrictions']['min_zero_crossings'],\n",
    "                                  config['pair_restrictions']['min_half_life'],\n",
    "                                  config['pair_restrictions']['hurst_threshold'])\n",
    "print('{} of the {} pairs with positive returns identified in the training set are also cointegrated in the test set'.format(\\\n",
    "    len(profitable_pairs_overlapped), len(profitable_pairs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is cointegration really important?\n",
    "\n",
    "To answer this question we will see how many of the still cointegrated pairs had positive and negative returns. We will then do the same for those pairs that were not cointegrated. \n",
    "\n",
    "If both are as likely to have positive and negative returns, then it means cointegration is not as important of a condition. On the other hand, if we verify that all pairs that are still cointegrated turned out to be profitable and those that are not anymore led to consistent negative returns, we can infer that cointegration is a very important predictor of future returns.\n",
    "\n",
    "We also compare the average performance of the two groups two see the relevance of being cointegrated with respect to the sharpe ratio obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Still cointegrated*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution for pairs which were cointegrated in train and test\n",
    "sharpe_results_pairs_overlapped = np.asarray([sharpe_results_kalman_test[index] for index \\\n",
    "                                              in profitable_pairs_overlapped_index])\n",
    "cum_returns_pairs_overlapped = np.asarray([cum_returns_kalman_test[index] for index \\\n",
    "                                              in profitable_pairs_overlapped_index])\n",
    "\n",
    "if len(sharpe_results_pairs_overlapped)>0:\n",
    "    _,_,_,_ = trader.calculate_metrics(sharpe_results_pairs_overlapped, cum_returns_pairs_overlapped,\n",
    "                                   n_years_test)\n",
    "else:\n",
    "    print('0% of the pairs cointegrated in the train are also cointegrated in the test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Not cointegrated anymore*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution for pairs which were cointegrated in train but not in test\n",
    "profitable_pairs_not_overlapped_index = [i for i in np.arange(0,len(profitable_pairs))\\\n",
    "                                         if i not in profitable_pairs_overlapped_index]\n",
    "\n",
    "sharpe_results_pairs_not_overlapped = np.asarray([sharpe_results_kalman_test[index] for index \\\n",
    "                                              in profitable_pairs_not_overlapped_index])\n",
    "\n",
    "cum_returns_pairs_not_overlapped = np.asarray([cum_returns_kalman_test[index] for index \\\n",
    "                                              in profitable_pairs_not_overlapped_index])\n",
    "\n",
    "_,_,_,_ = trader.calculate_metrics(sharpe_results_pairs_not_overlapped, cum_returns_pairs_not_overlapped,\n",
    "                                   n_years_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answering to the first question we were concerned with, we verify that a cointegrated pair is indeed more likely to have a positive return. Furthermore, we can conclude from the results that being cointegrated implied that those pairs generated higher returns. \n",
    "\n",
    "**TO REVIEW:Conclusion**: The fact that a pair is not cointegrated anymore does not impact the results obained. In fact, we just concluded that betting solely on the cointegrated pairs would yield a worse result. Therefore, we should not spend much effort in detecting pairs that are no cointegrated anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following with point number **2)**, we proceed to analyze the performance of the pairs that woud have been identified in the testing period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_test_date = config['dataset']['testing_initial_date']\n",
    "final_teste_date = config['dataset']['testing_final_date']\n",
    "\n",
    "# Get returns for test period\n",
    "df_returns_test = data_processor.get_return_series(df_prices_test)\n",
    "\n",
    "# APPLY PCA and CLUSTERING\n",
    "range_n_components = config['PCA']['N_COMPONENTS']\n",
    "X_test, clustered_series_all_test, clustered_series_test, counts_test, clf_test = \\\n",
    "            series_analyser.clustering_for_optimal_PCA(range_n_components[0], range_n_components[1],\n",
    "                                                       df_returns_test, config['clustering'])\n",
    "# Find pairs\n",
    "pairs_test, unique_tickers_test = series_analyser.get_candidate_pairs(\\\n",
    "                                            clustered_series=clustered_series_test,\n",
    "                                            pricing_df_train=df_prices_test,\n",
    "                                            pricing_df_test=df_prices_train,\n",
    "                                            min_half_life=config['pair_restrictions']['min_half_life'],\n",
    "                                            min_zero_crosings=config['pair_restrictions']['min_zero_crossings'],\n",
    "                                            p_value_threshold=config['pair_restrictions']['p_value_threshold'],\n",
    "                                            hurst_threshold=config['pair_restrictions']['hurst_threshold']\n",
    "                                            )\n",
    "\n",
    "# Finally, see overlap\n",
    "pairs_overlapped, pairs_overlapped_index = series_analyser.pairs_overlap(pairs_test,\n",
    "                                  config['pair_restrictions']['p_value_threshold'],\n",
    "                                  config['pair_restrictions']['min_zero_crossings'],\n",
    "                                  config['pair_restrictions']['min_half_life'],\n",
    "                                  config['pair_restrictions']['hurst_threshold'])\n",
    "print('{} of the {} pairs identified in the test set are also cointegrated in the training set'.format(\\\n",
    "    len(pairs_overlapped), len(pairs_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the pairs identified in the test period lead indeed to improved results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sharpe_results_kalman_test_newpairs, cum_returns_kalman_test_newpairs, performance_kalman_test_newpairs =\\\n",
    "    trader.apply_kalman_strategy(pairs_test, entry_multiplier,exit_multiplier,trading_filter, test_mode=False)\n",
    "\n",
    "_,_,_,_ = trader.calculate_metrics(sharpe_results_kalman_test_newpairs, cum_returns_kalman_test_newpairs,\n",
    "                                   n_years_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sharpe ratio is higher in this scenatio. Note hoewever, that the annual ROI is not so high as the pairs identified previously. This might be linked with the fact that these pairs did not prove to be cointegrated for a period as long as the other and therefore the pairs might be less stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the influence of pairs statistics\n",
    "\n",
    "It's interesting to analyze whether we could have used extra information from the pairs trading statistic, instead of considering it just as a pass or not pass test. `Law 2017` explore this concept on their paper (htey basically rank pairs according to a trade off between t-statistic and spread deviation from its mean). However, what we see below is that there is no obvious influence of any parameter in the performance of the corresponding pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_summary.corr()[['sharpe_result', 'positive_trades_per_pair_pct']].loc[['t_statistic', 'p_value',\n",
    "                                                                             'zero_cross', 'half_life',\n",
    "                                                                             'hurst_exponent']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Correlation Filter\n",
    "\n",
    "The correlation filter aims to track how the correlation between the two legs of tha pair is varing, and provide that information as input to the trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_pair = failed_pairs[2]\n",
    "\n",
    "example_pair_leg1 = example_pair[0][0]\n",
    "example_pair_leg2 = example_pair[0][1]\n",
    "\n",
    "example_pair_prices = etfs_pricing[[example_pair_leg1, example_pair_leg2]]\n",
    "example_pair_prices.plot(figsize=(15,5))\n",
    "\n",
    "\n",
    "# proceed to calculate correlation\n",
    "rolling_window = config['trading']['lookback_multiplier']*example_pair[0][2]['half_life']\n",
    "\n",
    "# get returns\n",
    "example_pair_returns = data_processor.get_return_series(example_pair_prices)\n",
    "\n",
    "# analyze correlation on returns\n",
    "example_correlation = example_pair_returns[example_pair_leg1].rolling(rolling_window).corr(example_pair_returns[example_pair_leg2])\n",
    "\n",
    "# plot correlation of returns\n",
    "diff_example_correlation = example_correlation.diff(periods=1)\n",
    "#diff_example_correlation = diff_example_correlation*10\n",
    "diff_example_correlation.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result indicates there's almost no correlation between correlation diff and returns... Let's see how this result varies on average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_correlations = []\n",
    "for failure in failed_pairs:\n",
    "    failure_df = failure[1][failure[1].units != 0]\n",
    "    correlation = failure_df['ret'].corr(failure_df['correlation'])\n",
    "    failure_correlations.append(correlation)\n",
    "    \n",
    "print(np.mean(failure_correlations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we are not realyy interested in the correlation of the the diff column, but rather on the correlation with its sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_correlations = []\n",
    "for failure in failed_pairs:\n",
    "    failure_df = failure[1][failure[1].units != 0]\n",
    "    failure_df['diff_correlation_sign']=failure_df['diff_correlation'].apply(lambda row: -1 if row<0 else 1)\n",
    "    correlation = failure_df['ret'].corr(failure_df['diff_correlation_sign'])\n",
    "    failure_correlations.append(correlation)\n",
    "    \n",
    "print(np.mean(failure_correlations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use mutual information rather than correlation as the sign is discrete. What about the relation with the zscore evolution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze non-profitable pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpe_results_kalman_test = np.asarray(sharpe_results_kalman_test)\n",
    "negative_pairs_indices = np.argwhere(sharpe_results_kalman_test < 0)\n",
    "print('{} out of {} pairs turned out to be non-profitable'.format(len(negative_pairs_indices), len(pairs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some more information on the non-profitable pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_pairs = [pairs[i] for i in negative_pairs_indices.flatten()]\n",
    "negative_pairs = [(item[0], item[1]) for item in negative_pairs]\n",
    "negative_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To what clusters do these pairs belong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label_n in range(len(counts)):\n",
    "    elements_cluster_n = list(clustered_series[clustered_series == label_n].index)\n",
    "    etfs_cluster_n = etfs_unique[etfs_unique['Ticker'].isin(elements_cluster_n)]\n",
    "    for pair in negative_pairs:\n",
    "        if pair[0] in list(etfs_cluster_n.Ticker):\n",
    "            print('Pair {} belongs to cluster {}'.format(pair, label_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the statistics rank?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indices = np.flip(np.argsort(sharpe_results_bollinger), axis=0)\n",
    "\n",
    "# initialize list of lists \n",
    "data = []\n",
    "for index in sorted_indices:\n",
    "    # get number of positive and negative positions\n",
    "    position_returns = performance_bollinger[index][1].position_return\n",
    "    positive_positions = len(position_returns[position_returns>0])\n",
    "    negative_positions = len(position_returns[position_returns<0])\n",
    "    data.append([pairs[index][0],\n",
    "                 pairs[index][1],\n",
    "                 pairs[index][2]['t_statistic'],\n",
    "                 pairs[index][2]['p_value'],\n",
    "                 pairs[index][2]['zero_cross'],\n",
    "                 pairs[index][2]['half_life'],\n",
    "                 pairs[index][2]['hurst_exponent'],\n",
    "                 positive_positions,\n",
    "                 negative_positions,\n",
    "                 sharpe_results_bollinger[index]\n",
    "                ])\n",
    "      \n",
    "# Create the pandas DataFrame \n",
    "df = pd.DataFrame(data, columns = ['Leg1', 'Leg2', 't_statistic', 'p_value', 'zero_cross',\n",
    "                                   'half_life', 'hurst_exponent', 'positive trades', 'negative_trades',\n",
    "                                   'sharpe_result']) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.half_life.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze correlations\n",
    "print('Half-life vs Sharpe Ratio correlation: ', df['sharpe_result'].corr(df['half_life']))\n",
    "print('Zero crossings vs Sharpe Ratio correlation: ', df['sharpe_result'].corr(df['zero_cross']))\n",
    "print('p-value vs Sharpe Ratio correlation: ', df['sharpe_result'].corr(df['p_value']))\n",
    "print('t-statistic vs Sharpe Ratio correlation: ', df['sharpe_result'].corr(df['t_statistic']))\n",
    "print('Hurst exponent vs Sharpe Ratio correlation ', df['sharpe_result'].corr(df['hurst_exponent']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there any signs these pairs were not profitable as the strategy evolves? Could we have predicted their lack of profitability?\n",
    "- Using a ML algorithm that recognizes when a pair is not profitable anymore.\n",
    "- Checking how the hurst exponent has been changing.\n",
    "- Analyze their previous positions' returns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
