{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A benchmark Pairs Trading strategy \n",
    "\n",
    "This notebook explores a pairs trading strategy using bollinger bands. This projected is being developed as part of a master thesis for the degree of Electrical and Computer Engineering.\n",
    "\n",
    "**Author:** Sim√£o Moraes Sarmento <br /> \n",
    "**Contact:** simaosarmento@hotmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "This notebook requires code from:\n",
    "\n",
    "Python files:\n",
    "- `class_SeriesAnalyser.py` - contains a set of functions to deal with time series analysis.\n",
    "- `class_Trader.py` - contains a set of functions concerning trading strategies.\n",
    "- `class_DataProcessor.py` - contains a set of functions concerning the data pre processing.\n",
    "\n",
    "Pickle files:\n",
    "- pickle file containing pairs to be traded (obtained from running `PairsTrading_CommodityETFs-Clustering.ipynb`)\n",
    "\n",
    "As a good practise, the notebook solely intends to exemplify the application of different trading strategies for different dataset examples, rather than coding the strategies theirselves. Please look into the files menitoned above for more detailed info on how the functions are built."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import json\n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import coint, adfuller\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Import Datetime and the Pandas DataReader\n",
    "from datetime import datetime\n",
    "from pandas_datareader import data, wb\n",
    "\n",
    "# Import alpha vantage\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "\n",
    "# Import scikit instruments\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# just set the seed for the random number generator\n",
    "np.random.seed(107)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = 'config/config_commodities_2010_2019.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_file, 'r') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config['dataset']['ticker_segment_dict'], 'rb') as handle:\n",
    "    ticker_segment_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%aimport class_SeriesAnalyser, class_Trader, class_DataProcessor\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_analyser = class_SeriesAnalyser.SeriesAnalyser()\n",
    "trader = class_Trader.Trader()\n",
    "data_processor = class_DataProcessor.DataProcessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve prices data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by retrieving the data from a Dataframe saved in a pickle file, as it was previously processed in the `PairsTrading_CommodityETFS_Datapreprocessing.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intraday\n",
    "df_prices = pd.read_pickle('data/etfs/pickle/commodity_ETFs_from_2014_complete.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 116 tickers\n",
      "Total of 105 tickers after removing tickers with Nan values\n"
     ]
    }
   ],
   "source": [
    "# split data in training and test\n",
    "df_prices_train, df_prices_test = data_processor.split_data(df_prices,\n",
    "                                                            ('01-01-2013',\n",
    "                                                             '31-12-2015'),\n",
    "                                                            ('01-01-2016',\n",
    "                                                             '31-12-2016'),\n",
    "                                                            remove_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78222"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_prices_train)+len(df_prices_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intra day\n",
    "#with open('data/etfs/pickle/pairs_unfiltered_intraday.pickle', 'rb') as handle:\n",
    "#    pairs = pickle.load(handle)\n",
    "\n",
    "#with open('data/etfs/pickle/pairs_category_intraday.pickle', 'rb') as handle:\n",
    "#with open('data/etfs/pickle/2013-2017/pairs_category_intraday.pickle', 'rb') as handle:\n",
    "#    pairs = pickle.load(handle)\n",
    "\n",
    "with open('data/etfs/pickle/2013-2017/pairs_unsupervised_learning_optical_intraday.pickle', 'rb') as handle:\n",
    "    pairs = pickle.load(handle)\n",
    "    \n",
    "# interday  \n",
    "#with open('data/etfs/pickle/pairs_unfiltered_interday.pickle', 'rb') as handle:\n",
    "#    pairs = pickle.load(handle)\n",
    "\n",
    "#with open('data/etfs/pickle/pairs_category_interday.pickle', 'rb') as handle:\n",
    "#    pairs = pickle.load(handle)\n",
    "\n",
    "#with open('data/etfs/pickle/pairs_unsupervised_learning_interday.pickle', 'rb') as handle:\n",
    "#    pairs = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### lookback_multiplier= config['trading']['lookback_multiplier']\n",
    "entry_multiplier= config['trading']['entry_multiplier']\n",
    "exit_multiplier= config['trading']['exit_multiplier']\n",
    "# obtain trading filter info\n",
    "if config['trading_filter']['active'] == 1:\n",
    "    trading_filter = config['trading_filter']\n",
    "else:\n",
    "    trading_filter = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply trading strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying the fixed beta strategy in validation period**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_split = '2015-01-01'\n",
    "\n",
    "# intraday\n",
    "n_years_val = round(len(df_prices_train[train_val_split:])/(240*78))\n",
    "\n",
    "# interday\n",
    "#n_years_val = round(len(df_prices_train)/(240))\n",
    "\n",
    "n_years_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " entry delay turned on.\n",
      "Pair: 25/25"
     ]
    }
   ],
   "source": [
    "entry_multiplier= config['trading']['entry_multiplier']\n",
    "exit_multiplier= config['trading']['exit_multiplier']\n",
    "train_results_without_costs, train_results_with_costs, performance_threshold_train = \\\n",
    "        trader.apply_trading_strategy(pairs, \n",
    "                                       'fixed_beta',\n",
    "                                        2,#entry_multiplier,\n",
    "                                        0,#exit_multiplier,\n",
    "                                        test_mode=False,\n",
    "                                        train_val_split=train_val_split\n",
    "                                       )\n",
    "\n",
    "sharpe_results_threshold_train_nocosts, cum_returns_threshold_train_nocosts = train_results_without_costs\n",
    "sharpe_results_threshold_train_w_costs, cum_returns_threshold_train_w_costs = train_results_with_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average result:  0.9806381794083597\n",
      "avg_annual_roi:  9.831532726412773\n",
      "88.0 % of the pairs had positive returns\n"
     ]
    }
   ],
   "source": [
    "# WARNING: MUST CHANGE SHARPE RATIO\n",
    "avg_sharpe_train, total_roi_train, anual_roi_train, positive_pct_train = \\\n",
    "    trader.calculate_metrics(sharpe_results_threshold_train_w_costs, cum_returns_threshold_train_w_costs,\n",
    "                             n_years_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio Distribution: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12e017e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Sharpe Ratio Distribution: ')\n",
    "n, bins, patches = plt.hist(sharpe_results_threshold_train_w_costs, bins = 16, normed=True, orientation='vertical',\n",
    "                            color='red', rwidth=0.9, align='mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cum_returns_threshold_train_w_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00065216, 1.85857758, 1.82650352, 2.38656782, 0.23761356,\n",
       "       2.43057765, 0.34742619, 1.64568947, 0.40169478, 1.97136786,\n",
       "       0.6740714 , 1.16529968, 0.66825491, 0.30150536, 0.44739192,\n",
       "       0.77402251, 1.67031283, 0.46674424, 4.27945843, 1.95294305,\n",
       "       0.66013011, 2.76642467, 0.71078962, 0.70179919, 1.06348963])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas = list()\n",
    "for i in range(len(pairs)):\n",
    "    betas.append(pairs[i][2]['coint_coef'])\n",
    "np.asarray(betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average result:  0.9806381794083597\n",
      "avg_annual_roi:  9.831532726412773\n",
      "88.0 % of the pairs had positive returns\n"
     ]
    }
   ],
   "source": [
    "results_training, pairs_summary_training = trader.summarize_results(sharpe_results_threshold_train_w_costs,\n",
    "                                                                    cum_returns_threshold_train_w_costs,\n",
    "                                                                    performance_threshold_train,\n",
    "                                                                    pairs,\n",
    "                                                                    ticker_segment_dict, n_years_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out of Sample Analysis\n",
    "\n",
    "In this section, we analyze the performance of the strategy in the validation dataset. \n",
    "\n",
    "We proceed with some data exploration analysis. For this purpose we will do the following:\n",
    "\n",
    "- Analyze which percentage of the identified pairs are still cointegrated in the validation period.\n",
    "- Analyze which percentage of pairs have positive returns, and how many of those are still cointegrated.\n",
    "- Analyze how many new pais were not identified to be cointegrated up to the validation period.\n",
    "- Run strategy for identified pairs in training period.\n",
    "\n",
    "This analysis will help us getting some insight into how the cointegrated pairs vary from time to time, and therefore how we should allocate our resources to predict when pairs are not cointegrated anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the Strategy out-of Sample\n",
    "\n",
    "We might want to apply the strategy in all pairs identified. Or, instead, we might prefer to apply the strategy only on those pairs that turned out to be profitable. Let's compare how both approaches work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intraday\n",
    "n_years_test = round(len(df_prices_test)/(240*78))\n",
    "\n",
    "# interday\n",
    "#n_years_test = round(len(df_prices_test)/(240))\n",
    "\n",
    "n_years_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1: Unrestricted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic Threshold Strategy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " entry delay turned on.\n",
      "Pair: 25/25"
     ]
    }
   ],
   "source": [
    "results_without_costs, results_with_costs, performance_threshold_test = \\\n",
    "                            trader.apply_trading_strategy(pairs, \n",
    "                                                           'fixed_beta',\n",
    "                                                            2,#entry_multiplier,\n",
    "                                                            0,#exit_multiplier,\n",
    "                                                            test_mode=True,\n",
    "                                                            train_val_split=train_val_split\n",
    "                                                           )\n",
    "sharpe_results_threshold_test_nocosts, cum_returns_threshold_test_nocosts = results_without_costs\n",
    "sharpe_results_threshold_test_w_costs, cum_returns_threshold_test_w_costs = results_with_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average result:  0.8042495447942938\n",
      "avg_annual_roi:  11.268798200340125\n",
      "76.0 % of the pairs had positive returns\n"
     ]
    }
   ],
   "source": [
    "_, _, _, _ = trader.calculate_metrics(sharpe_results_threshold_test_w_costs, cum_returns_threshold_test_w_costs,\n",
    "                                      n_years_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: Keeping only pairs that had positive returns in the training period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_returns_threshold_train_w_costs = np.asarray(cum_returns_threshold_train_w_costs)\n",
    "profitable_pairs_indices = np.argwhere(cum_returns_threshold_train_w_costs > 0)\n",
    "profitable_pairs = [pairs[i] for i in profitable_pairs_indices.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " entry delay turned on.\n",
      "Pair: 22/22"
     ]
    }
   ],
   "source": [
    "results_without_costs, results_with_costs, performance_threshold_test = \\\n",
    "                            trader.apply_trading_strategy(profitable_pairs, \n",
    "                                                           'fixed_beta',\n",
    "                                                            2,#entry_multiplier,\n",
    "                                                            0,#exit_multiplier,\n",
    "                                                            test_mode=True,\n",
    "                                                            train_val_split=train_val_split\n",
    "                                                           )\n",
    "sharpe_results_threshold_test_nocosts, cum_returns_threshold_test_nocosts = results_without_costs\n",
    "sharpe_results_threshold_test_w_costs, cum_returns_threshold_test_w_costs = results_with_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average result:  0.9821406664781306\n",
      "avg_annual_roi:  13.227041119939575\n",
      "81.81818181818181 % of the pairs had positive returns\n"
     ]
    }
   ],
   "source": [
    "_, _, _, _ = trader.calculate_metrics(sharpe_results_threshold_test_w_costs, cum_returns_threshold_test_w_costs,\n",
    "                                      n_years_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 3: Keeping only top 10 pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpe_results_threshold_train_w_costs = np.asarray(sharpe_results_threshold_train_w_costs)\n",
    "sorted_pairs_indices = np.argsort(sharpe_results_threshold_train_w_costs)[::-1][:10]\n",
    "top_10_pairs = [pairs[i] for i in sorted_pairs_indices.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting by returns seems to give better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_returns_threshold_train_w_costs = np.asarray(cum_returns_threshold_train_w_costs)\n",
    "sorted_pairs_indices = np.argsort(cum_returns_threshold_train_w_costs)[::-1][:10]\n",
    "top_10_pairs = [pairs[i] for i in sorted_pairs_indices.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " entry delay turned on.\n",
      "Pair: 10/10"
     ]
    }
   ],
   "source": [
    "results_without_costs, results_with_costs, performance_threshold_test = \\\n",
    "                            trader.apply_trading_strategy(top_10_pairs, \n",
    "                                                           'fixed_beta',\n",
    "                                                            2,#entry_multiplier,\n",
    "                                                            0,#exit_multiplier,\n",
    "                                                            test_mode=True,\n",
    "                                                            train_val_split=train_val_split\n",
    "                                                           )\n",
    "sharpe_results_threshold_test_nocosts, cum_returns_threshold_test_nocosts = results_without_costs\n",
    "sharpe_results_threshold_test_w_costs, cum_returns_threshold_test_w_costs = results_with_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average result:  1.3831330201486485\n",
      "avg_annual_roi:  21.298923836450335\n",
      "90.0 % of the pairs had positive returns\n"
     ]
    }
   ],
   "source": [
    "_, _, _, _ = trader.calculate_metrics(sharpe_results_threshold_test_w_costs, cum_returns_threshold_test_w_costs,\n",
    "                                      n_years_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average result:  1.3831330201486485\n",
      "avg_annual_roi:  21.298923836450335\n",
      "90.0 % of the pairs had positive returns\n"
     ]
    }
   ],
   "source": [
    "results, pairs_summary = trader.summarize_results(sharpe_results_threshold_test_w_costs,\n",
    "                                                  cum_returns_threshold_test_w_costs,\n",
    "                                                  performance_threshold_test,\n",
    "                                                  top_10_pairs, ticker_segment_dict,\n",
    "                                                  n_years_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Leg1</th>\n",
       "      <th>Leg1_Segmt</th>\n",
       "      <th>Leg2</th>\n",
       "      <th>Leg2_Segmt</th>\n",
       "      <th>t_statistic</th>\n",
       "      <th>p_value</th>\n",
       "      <th>zero_cross</th>\n",
       "      <th>half_life</th>\n",
       "      <th>hurst_exponent</th>\n",
       "      <th>positive_trades</th>\n",
       "      <th>negative_trades</th>\n",
       "      <th>sharpe_result</th>\n",
       "      <th>positive_trades_per_pair_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BCM</td>\n",
       "      <td>Commodities: Broad Market</td>\n",
       "      <td>DJCI</td>\n",
       "      <td>Commodities: Broad Market</td>\n",
       "      <td>-3.181025</td>\n",
       "      <td>0.021110</td>\n",
       "      <td>457</td>\n",
       "      <td>92</td>\n",
       "      <td>0.279985</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3.112840</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PICK</td>\n",
       "      <td>Equity: Global Metals &amp; Mining</td>\n",
       "      <td>YMLP</td>\n",
       "      <td>Equity: U.S. MLPs</td>\n",
       "      <td>-4.552308</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>618</td>\n",
       "      <td>673</td>\n",
       "      <td>0.390220</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.174554</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IXC</td>\n",
       "      <td>Equity: Global Energy</td>\n",
       "      <td>PXE</td>\n",
       "      <td>Equity: U.S. Oil &amp; Gas Exploration &amp; Production</td>\n",
       "      <td>-3.636076</td>\n",
       "      <td>0.005108</td>\n",
       "      <td>592</td>\n",
       "      <td>528</td>\n",
       "      <td>0.382899</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.133332</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PXE</td>\n",
       "      <td>Equity: U.S. Oil &amp; Gas Exploration &amp; Production</td>\n",
       "      <td>PXI</td>\n",
       "      <td>Equity: U.S. Energy</td>\n",
       "      <td>-3.729752</td>\n",
       "      <td>0.003714</td>\n",
       "      <td>702</td>\n",
       "      <td>214</td>\n",
       "      <td>0.286382</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.925801</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DGP</td>\n",
       "      <td>Leveraged Commodities: Precious Metals Gold</td>\n",
       "      <td>SLV</td>\n",
       "      <td>Commodities: Precious Metals Silver</td>\n",
       "      <td>-3.639337</td>\n",
       "      <td>0.005052</td>\n",
       "      <td>391</td>\n",
       "      <td>1265</td>\n",
       "      <td>0.477973</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.610271</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DBS</td>\n",
       "      <td>Commodities: Precious Metals Silver</td>\n",
       "      <td>DGP</td>\n",
       "      <td>Leveraged Commodities: Precious Metals Gold</td>\n",
       "      <td>-3.371320</td>\n",
       "      <td>0.011976</td>\n",
       "      <td>335</td>\n",
       "      <td>710</td>\n",
       "      <td>0.385646</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.950607</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AMLP</td>\n",
       "      <td>Equity: U.S. MLPs</td>\n",
       "      <td>MLPI</td>\n",
       "      <td>Equity: U.S. MLPs</td>\n",
       "      <td>-2.869763</td>\n",
       "      <td>0.048979</td>\n",
       "      <td>5979</td>\n",
       "      <td>92</td>\n",
       "      <td>0.293217</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.886740</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DJCI</td>\n",
       "      <td>Commodities: Broad Market</td>\n",
       "      <td>SOYB</td>\n",
       "      <td>Commodities: Agriculture Soybeans</td>\n",
       "      <td>-3.212308</td>\n",
       "      <td>0.019283</td>\n",
       "      <td>297</td>\n",
       "      <td>392</td>\n",
       "      <td>0.330344</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.587238</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BCM</td>\n",
       "      <td>Commodities: Broad Market</td>\n",
       "      <td>SOYB</td>\n",
       "      <td>Commodities: Agriculture Soybeans</td>\n",
       "      <td>-3.111962</td>\n",
       "      <td>0.025681</td>\n",
       "      <td>295</td>\n",
       "      <td>503</td>\n",
       "      <td>0.351337</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.449947</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SOYB</td>\n",
       "      <td>Commodities: Agriculture Soybeans</td>\n",
       "      <td>WEAT</td>\n",
       "      <td>Commodities: Agriculture Wheat</td>\n",
       "      <td>-2.959747</td>\n",
       "      <td>0.038828</td>\n",
       "      <td>264</td>\n",
       "      <td>914</td>\n",
       "      <td>0.348989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Leg1                                       Leg1_Segmt  Leg2  \\\n",
       "0   BCM                        Commodities: Broad Market  DJCI   \n",
       "1  PICK                   Equity: Global Metals & Mining  YMLP   \n",
       "2   IXC                            Equity: Global Energy   PXE   \n",
       "3   PXE  Equity: U.S. Oil & Gas Exploration & Production   PXI   \n",
       "4   DGP      Leveraged Commodities: Precious Metals Gold   SLV   \n",
       "5   DBS              Commodities: Precious Metals Silver   DGP   \n",
       "6  AMLP                                Equity: U.S. MLPs  MLPI   \n",
       "7  DJCI                        Commodities: Broad Market  SOYB   \n",
       "8   BCM                        Commodities: Broad Market  SOYB   \n",
       "9  SOYB                Commodities: Agriculture Soybeans  WEAT   \n",
       "\n",
       "                                        Leg2_Segmt  t_statistic   p_value  \\\n",
       "0                        Commodities: Broad Market    -3.181025  0.021110   \n",
       "1                                Equity: U.S. MLPs    -4.552308  0.000158   \n",
       "2  Equity: U.S. Oil & Gas Exploration & Production    -3.636076  0.005108   \n",
       "3                              Equity: U.S. Energy    -3.729752  0.003714   \n",
       "4              Commodities: Precious Metals Silver    -3.639337  0.005052   \n",
       "5      Leveraged Commodities: Precious Metals Gold    -3.371320  0.011976   \n",
       "6                                Equity: U.S. MLPs    -2.869763  0.048979   \n",
       "7                Commodities: Agriculture Soybeans    -3.212308  0.019283   \n",
       "8                Commodities: Agriculture Soybeans    -3.111962  0.025681   \n",
       "9                   Commodities: Agriculture Wheat    -2.959747  0.038828   \n",
       "\n",
       "   zero_cross  half_life  hurst_exponent  positive_trades  negative_trades  \\\n",
       "0         457         92        0.279985               15                0   \n",
       "1         618        673        0.390220                1                0   \n",
       "2         592        528        0.382899                2                0   \n",
       "3         702        214        0.286382                2                0   \n",
       "4         391       1265        0.477973                1                0   \n",
       "5         335        710        0.385646                1                0   \n",
       "6        5979         92        0.293217                1                0   \n",
       "7         297        392        0.330344                1                0   \n",
       "8         295        503        0.351337                1                0   \n",
       "9         264        914        0.348989                0                0   \n",
       "\n",
       "   sharpe_result  positive_trades_per_pair_pct  \n",
       "0       3.112840                         100.0  \n",
       "1       2.174554                         100.0  \n",
       "2       2.133332                         100.0  \n",
       "3       1.925801                         100.0  \n",
       "4       1.610271                         100.0  \n",
       "5       0.950607                         100.0  \n",
       "6       0.886740                         100.0  \n",
       "7       0.587238                         100.0  \n",
       "8       0.449947                         100.0  \n",
       "9       0.000000                           NaN  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Pairs' Overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There could be two possible interpretations for pairs' overlap.\n",
    "1. We might be interested in checking which of the cointegrated pairs found in the training dataset are also cointegrated in the test set; Furthermore we want to explore how the two types of pairs perform.\n",
    "2. We might be interested in finding if the pairs that would have been found in the test set by performing PCA + clustering would be cointegrated in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with **1)**, let's see how many of the identified pairs actually turned out to be cointegrated during this period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_overlapped, pairs_overlapped_index = series_analyser.pairs_overlap(pairs,\n",
    "                                  config['pair_restrictions']['p_value_threshold'],\n",
    "                                  config['pair_restrictions']['min_zero_crossings'],\n",
    "                                  config['pair_restrictions']['min_half_life'],\n",
    "                                  config['pair_restrictions']['hurst_threshold'])\n",
    "print('{} of the {} pairs identified in the training set are also cointegrated in the test set'.format(\\\n",
    "    len(pairs_overlapped), len(pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profitable_pairs_overlapped, profitable_pairs_overlapped_index = series_analyser.pairs_overlap(profitable_pairs,\n",
    "                                  config['pair_restrictions']['p_value_threshold'],\n",
    "                                  config['pair_restrictions']['min_zero_crossings'],\n",
    "                                  config['pair_restrictions']['min_half_life'],\n",
    "                                  config['pair_restrictions']['hurst_threshold'])\n",
    "print('{} of the {} pairs with positive returns identified in the training set are also cointegrated in the test set'.format(\\\n",
    "    len(profitable_pairs_overlapped), len(profitable_pairs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is cointegration really important?\n",
    "\n",
    "To answer this question we will see how many of the still cointegrated pairs had positive and negative returns. We will then do the same for those pairs that were not cointegrated. \n",
    "\n",
    "If both are as likely to have positive and negative returns, then it means cointegration is not as important of a condition. On the other hand, if we verify that all pairs that are still cointegrated turned out to be profitable and those that are not anymore led to consistent negative returns, we can infer that cointegration is a very important predictor of future returns.\n",
    "\n",
    "We also compare the average performance of the two groups two see the relevance of being cointegrated with respect to the sharpe ratio obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Still cointegrated*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution for pairs which were cointegrated in train and test\n",
    "sharpe_results_pairs_overlapped = np.asarray([sharpe_results_kalman_test[index] for index \\\n",
    "                                              in profitable_pairs_overlapped_index])\n",
    "cum_returns_pairs_overlapped = np.asarray([cum_returns_kalman_test[index] for index \\\n",
    "                                              in profitable_pairs_overlapped_index])\n",
    "\n",
    "if len(sharpe_results_pairs_overlapped)>0:\n",
    "    _,_,_,_ = trader.calculate_metrics(sharpe_results_pairs_overlapped, cum_returns_pairs_overlapped,\n",
    "                                   n_years_test)\n",
    "else:\n",
    "    print('0% of the pairs cointegrated in the train are also cointegrated in the test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Not cointegrated anymore*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution for pairs which were cointegrated in train but not in test\n",
    "profitable_pairs_not_overlapped_index = [i for i in np.arange(0,len(profitable_pairs))\\\n",
    "                                         if i not in profitable_pairs_overlapped_index]\n",
    "\n",
    "sharpe_results_pairs_not_overlapped = np.asarray([sharpe_results_kalman_test[index] for index \\\n",
    "                                              in profitable_pairs_not_overlapped_index])\n",
    "\n",
    "cum_returns_pairs_not_overlapped = np.asarray([cum_returns_kalman_test[index] for index \\\n",
    "                                              in profitable_pairs_not_overlapped_index])\n",
    "\n",
    "_,_,_,_ = trader.calculate_metrics(sharpe_results_pairs_not_overlapped, cum_returns_pairs_not_overlapped,\n",
    "                                   n_years_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answering to the first question we were concerned with, we verify that a cointegrated pair is indeed more likely to have a positive return. Furthermore, we can conclude from the results that being cointegrated implied that those pairs generated higher returns. \n",
    "\n",
    "**TO REVIEW:Conclusion**: The fact that a pair is not cointegrated anymore does not impact the results obained. In fact, we just concluded that betting solely on the cointegrated pairs would yield a worse result. Therefore, we should not spend much effort in detecting pairs that are no cointegrated anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following with point number **2)**, we proceed to analyze the performance of the pairs that woud have been identified in the testing period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_test_date = config['dataset']['testing_initial_date']\n",
    "final_teste_date = config['dataset']['testing_final_date']\n",
    "\n",
    "# Get returns for test period\n",
    "df_returns_test = data_processor.get_return_series(df_prices_test)\n",
    "\n",
    "# APPLY PCA and CLUSTERING\n",
    "range_n_components = config['PCA']['N_COMPONENTS']\n",
    "X_test, clustered_series_all_test, clustered_series_test, counts_test, clf_test = \\\n",
    "            series_analyser.clustering_for_optimal_PCA(range_n_components[0], range_n_components[1],\n",
    "                                                       df_returns_test, config['clustering'])\n",
    "# Find pairs\n",
    "pairs_test, unique_tickers_test = series_analyser.get_candidate_pairs(\\\n",
    "                                            clustered_series=clustered_series_test,\n",
    "                                            pricing_df_train=df_prices_test,\n",
    "                                            pricing_df_test=df_prices_train,\n",
    "                                            min_half_life=config['pair_restrictions']['min_half_life'],\n",
    "                                            min_zero_crosings=config['pair_restrictions']['min_zero_crossings'],\n",
    "                                            p_value_threshold=config['pair_restrictions']['p_value_threshold'],\n",
    "                                            hurst_threshold=config['pair_restrictions']['hurst_threshold']\n",
    "                                            )\n",
    "\n",
    "# Finally, see overlap\n",
    "pairs_overlapped, pairs_overlapped_index = series_analyser.pairs_overlap(pairs_test,\n",
    "                                  config['pair_restrictions']['p_value_threshold'],\n",
    "                                  config['pair_restrictions']['min_zero_crossings'],\n",
    "                                  config['pair_restrictions']['min_half_life'],\n",
    "                                  config['pair_restrictions']['hurst_threshold'])\n",
    "print('{} of the {} pairs identified in the test set are also cointegrated in the training set'.format(\\\n",
    "    len(pairs_overlapped), len(pairs_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the pairs identified in the test period lead indeed to improved results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sharpe_results_kalman_test_newpairs, cum_returns_kalman_test_newpairs, performance_kalman_test_newpairs =\\\n",
    "    trader.apply_kalman_strategy(pairs_test, entry_multiplier,exit_multiplier,trading_filter, test_mode=False)\n",
    "\n",
    "_,_,_,_ = trader.calculate_metrics(sharpe_results_kalman_test_newpairs, cum_returns_kalman_test_newpairs,\n",
    "                                   n_years_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sharpe ratio is higher in this scenatio. Note hoewever, that the annual ROI is not so high as the pairs identified previously. This might be linked with the fact that these pairs did not prove to be cointegrated for a period as long as the other and therefore the pairs might be less stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the influence of pairs statistics\n",
    "\n",
    "It's interesting to analyze whether we could have used extra information from the pairs trading statistic, instead of considering it just as a pass or not pass test. `Law 2017` explore this concept on their paper (htey basically rank pairs according to a trade off between t-statistic and spread deviation from its mean). However, what we see below is that there is no obvious influence of any parameter in the performance of the corresponding pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_summary.corr()[['sharpe_result', 'positive_trades_per_pair_pct']].loc[['t_statistic', 'p_value',\n",
    "                                                                             'zero_cross', 'half_life',\n",
    "                                                                             'hurst_exponent']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Correlation Filter\n",
    "\n",
    "The correlation filter aims to track how the correlation between the two legs of tha pair is varing, and provide that information as input to the trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_pair = failed_pairs[2]\n",
    "\n",
    "example_pair_leg1 = example_pair[0][0]\n",
    "example_pair_leg2 = example_pair[0][1]\n",
    "\n",
    "example_pair_prices = etfs_pricing[[example_pair_leg1, example_pair_leg2]]\n",
    "example_pair_prices.plot(figsize=(15,5))\n",
    "\n",
    "\n",
    "# proceed to calculate correlation\n",
    "rolling_window = config['trading']['lookback_multiplier']*example_pair[0][2]['half_life']\n",
    "\n",
    "# get returns\n",
    "example_pair_returns = data_processor.get_return_series(example_pair_prices)\n",
    "\n",
    "# analyze correlation on returns\n",
    "example_correlation = example_pair_returns[example_pair_leg1].rolling(rolling_window).corr(example_pair_returns[example_pair_leg2])\n",
    "\n",
    "# plot correlation of returns\n",
    "diff_example_correlation = example_correlation.diff(periods=1)\n",
    "#diff_example_correlation = diff_example_correlation*10\n",
    "diff_example_correlation.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result indicates there's almost no correlation between correlation diff and returns... Let's see how this result varies on average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_correlations = []\n",
    "for failure in failed_pairs:\n",
    "    failure_df = failure[1][failure[1].units != 0]\n",
    "    correlation = failure_df['ret'].corr(failure_df['correlation'])\n",
    "    failure_correlations.append(correlation)\n",
    "    \n",
    "print(np.mean(failure_correlations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we are not realyy interested in the correlation of the the diff column, but rather on the correlation with its sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_correlations = []\n",
    "for failure in failed_pairs:\n",
    "    failure_df = failure[1][failure[1].units != 0]\n",
    "    failure_df['diff_correlation_sign']=failure_df['diff_correlation'].apply(lambda row: -1 if row<0 else 1)\n",
    "    correlation = failure_df['ret'].corr(failure_df['diff_correlation_sign'])\n",
    "    failure_correlations.append(correlation)\n",
    "    \n",
    "print(np.mean(failure_correlations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use mutual information rather than correlation as the sign is discrete. What about the relation with the zscore evolution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze non-profitable pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpe_results_kalman_test = np.asarray(sharpe_results_kalman_test)\n",
    "negative_pairs_indices = np.argwhere(sharpe_results_kalman_test < 0)\n",
    "print('{} out of {} pairs turned out to be non-profitable'.format(len(negative_pairs_indices), len(pairs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some more information on the non-profitable pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_pairs = [pairs[i] for i in negative_pairs_indices.flatten()]\n",
    "negative_pairs = [(item[0], item[1]) for item in negative_pairs]\n",
    "negative_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To what clusters do these pairs belong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label_n in range(len(counts)):\n",
    "    elements_cluster_n = list(clustered_series[clustered_series == label_n].index)\n",
    "    etfs_cluster_n = etfs_unique[etfs_unique['Ticker'].isin(elements_cluster_n)]\n",
    "    for pair in negative_pairs:\n",
    "        if pair[0] in list(etfs_cluster_n.Ticker):\n",
    "            print('Pair {} belongs to cluster {}'.format(pair, label_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the statistics rank?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indices = np.flip(np.argsort(sharpe_results_bollinger), axis=0)\n",
    "\n",
    "# initialize list of lists \n",
    "data = []\n",
    "for index in sorted_indices:\n",
    "    # get number of positive and negative positions\n",
    "    position_returns = performance_bollinger[index][1].position_return\n",
    "    positive_positions = len(position_returns[position_returns>0])\n",
    "    negative_positions = len(position_returns[position_returns<0])\n",
    "    data.append([pairs[index][0],\n",
    "                 pairs[index][1],\n",
    "                 pairs[index][2]['t_statistic'],\n",
    "                 pairs[index][2]['p_value'],\n",
    "                 pairs[index][2]['zero_cross'],\n",
    "                 pairs[index][2]['half_life'],\n",
    "                 pairs[index][2]['hurst_exponent'],\n",
    "                 positive_positions,\n",
    "                 negative_positions,\n",
    "                 sharpe_results_bollinger[index]\n",
    "                ])\n",
    "      \n",
    "# Create the pandas DataFrame \n",
    "df = pd.DataFrame(data, columns = ['Leg1', 'Leg2', 't_statistic', 'p_value', 'zero_cross',\n",
    "                                   'half_life', 'hurst_exponent', 'positive trades', 'negative_trades',\n",
    "                                   'sharpe_result']) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.half_life.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze correlations\n",
    "print('Half-life vs Sharpe Ratio correlation: ', df['sharpe_result'].corr(df['half_life']))\n",
    "print('Zero crossings vs Sharpe Ratio correlation: ', df['sharpe_result'].corr(df['zero_cross']))\n",
    "print('p-value vs Sharpe Ratio correlation: ', df['sharpe_result'].corr(df['p_value']))\n",
    "print('t-statistic vs Sharpe Ratio correlation: ', df['sharpe_result'].corr(df['t_statistic']))\n",
    "print('Hurst exponent vs Sharpe Ratio correlation ', df['sharpe_result'].corr(df['hurst_exponent']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there any signs these pairs were not profitable as the strategy evolves? Could we have predicted their lack of profitability?\n",
    "- Using a ML algorithm that recognizes when a pair is not profitable anymore.\n",
    "- Checking how the hurst exponent has been changing.\n",
    "- Analyze their previous positions' returns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
