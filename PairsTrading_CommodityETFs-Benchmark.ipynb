{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A benchmark Pairs Trading strategy \n",
    "\n",
    "This notebook explores a pairs trading strategy using bollinger bands. This projected is being developed as part of a master thesis for the degree of Electrical and Computer Engineering.\n",
    "\n",
    "**Author:** Sim√£o Moraes Sarmento <br /> \n",
    "**Contact:** simaosarmento@hotmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "This notebook requires code from:\n",
    "\n",
    "Python files:\n",
    "- `class_SeriesAnalyser.py` - contains a set of functions to deal with time series analysis.\n",
    "- `class_Trader.py` - contains a set of functions concerning trading strategies.\n",
    "- `class_DataProcessor.py` - contains a set of functions concerning the data pre processing.\n",
    "\n",
    "Pickle files:\n",
    "- pickle file containing pairs to be traded (obtained from running `PairsTrading_CommodityETFs-Clustering.ipynb`)\n",
    "\n",
    "As a good practise, the notebook solely intends to exemplify the application of different trading strategies for different dataset examples, rather than coding the strategies theirselves. Please look into the files menitoned above for more detailed info on how the functions are built."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import json\n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import coint, adfuller\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Import Datetime and the Pandas DataReader\n",
    "from datetime import datetime\n",
    "from pandas_datareader import data, wb\n",
    "\n",
    "# Import alpha vantage\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "\n",
    "# Import scikit instruments\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# just set the seed for the random number generator\n",
    "np.random.seed(107)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = 'config/config_commodities_2010_2019.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_file, 'r') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%aimport class_SeriesAnalyser, class_Trader, class_DataProcessor\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_analyser = class_SeriesAnalyser.SeriesAnalyser()\n",
    "trader = class_Trader.Trader()\n",
    "data_processor = class_DataProcessor.DataProcessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve prices data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by retrieving the data from a Dataframe saved in a pickle file, as it was previously processed in the `PairsTrading_CommodityETFS_Datapreprocessing.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intraday\n",
    "#df_prices = pd.read_pickle('data/etfs/pickle/commodity_ETFs_intraday')\n",
    "\n",
    "# inter day\n",
    "df_prices = pd.read_pickle('data/etfs/pickle/commodity_ETFs_long_updated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 208 tickers\n",
      "Total of 71 tickers after removing tickers with Nan values\n"
     ]
    }
   ],
   "source": [
    "# split data in training and test\n",
    "df_prices_train, df_prices_test = data_processor.split_data(df_prices,\n",
    "                                                            ('01-01-2009',\n",
    "                                                             '31-12-2017'),\n",
    "                                                            ('01-01-2018',\n",
    "                                                             '31-12-2018'),\n",
    "                                                            remove_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2516"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_prices_train)+len(df_prices_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('data/etfs/pickle/pairs_unfiltered.pickle', 'rb') as handle:\n",
    "#    pairs = pickle.load(handle)\n",
    "\n",
    "with open('data/etfs/pickle/pairs_category.pickle', 'rb') as handle:\n",
    "    pairs = pickle.load(handle)\n",
    "\n",
    "#with open('data/etfs/pickle/pairs_unsupervised_learning.pickle', 'rb') as handle:\n",
    "#    pairs = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback_multiplier= config['trading']['lookback_multiplier']\n",
    "entry_multiplier= config['trading']['entry_multiplier']\n",
    "exit_multiplier= config['trading']['exit_multiplier']\n",
    "# obtain trading filter info\n",
    "if config['trading_filter']['active'] == 1:\n",
    "    trading_filter = config['trading_filter']\n",
    "else:\n",
    "    trading_filter = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intraday\n",
    "#n_years_train = round(len(df_prices_train)/(240*78))\n",
    "\n",
    "# interday\n",
    "n_years_train = round(len(df_prices_train)/(240))\n",
    "\n",
    "n_years_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply trading strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying Bollinger Bands**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1/37\n",
      "\n",
      "2/37\n",
      "\n",
      "3/37\n",
      "\n",
      "4/37\n",
      "\n",
      "5/37\n",
      "\n",
      "6/37\n",
      "\n",
      "7/37\n",
      "\n",
      "8/37\n",
      "\n",
      "9/37\n",
      "\n",
      "10/37\n",
      "\n",
      "11/37\n",
      "\n",
      "12/37\n",
      "\n",
      "13/37\n",
      "\n",
      "14/37\n",
      "\n",
      "15/37\n",
      "\n",
      "16/37\n",
      "\n",
      "17/37\n",
      "\n",
      "18/37\n",
      "\n",
      "19/37\n",
      "\n",
      "20/37\n",
      "\n",
      "21/37\n",
      "\n",
      "22/37\n",
      "\n",
      "23/37\n",
      "\n",
      "24/37\n",
      "\n",
      "25/37\n",
      "\n",
      "26/37\n",
      "\n",
      "27/37\n",
      "\n",
      "28/37\n",
      "\n",
      "29/37\n",
      "\n",
      "30/37\n",
      "\n",
      "31/37\n",
      "\n",
      "32/37\n",
      "\n",
      "33/37\n",
      "\n",
      "34/37\n",
      "\n",
      "35/37\n",
      "\n",
      "36/37\n",
      "\n",
      "37/37\n"
     ]
    }
   ],
   "source": [
    "sharpe_results_bollinger, cum_returns_bollinger, performance_bollinger = trader.apply_bollinger_strategy(pairs,\n",
    "                                                                                         lookback_multiplier,\n",
    "                                                                                         entry_multiplier,\n",
    "                                                                                         exit_multiplier,\n",
    "                                                                                         trading_filter,\n",
    "                                                                                         test_mode=False\n",
    "                                                                                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bollinger Bands Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average result:  0.12605645648204064\n",
      "avg_annual_roi:  -0.6552746848666025\n",
      "59.45945945945946 % of the pairs had positive returns\n"
     ]
    }
   ],
   "source": [
    "avg_sharpe_bollinger, total_roi_bollinger, anual_roi_bollinger, positive_pct_bollinger = \\\n",
    "    trader.calculate_metrics(sharpe_results_bollinger, cum_returns_bollinger, n_years_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying the Kalman filter based strategy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair: 1/37\n",
      "Pair: 2/37\n",
      "Pair: 3/37\n",
      "Pair: 4/37\n",
      "Pair: 5/37\n",
      "Pair: 6/37\n",
      "Pair: 7/37\n",
      "Pair: 8/37\n",
      "Pair: 9/37\n",
      "Pair: 10/37\n",
      "Pair: 11/37\n",
      "Pair: 12/37\n",
      "Pair: 13/37\n",
      "Pair: 14/37\n",
      "Pair: 15/37\n",
      "Pair: 16/37\n",
      "Pair: 17/37\n",
      "Pair: 18/37\n",
      "Pair: 19/37\n",
      "Pair: 20/37\n",
      "Pair: 21/37\n",
      "Pair: 22/37\n",
      "Pair: 23/37\n",
      "Pair: 24/37\n",
      "Pair: 25/37\n",
      "Pair: 26/37\n",
      "Pair: 27/37\n",
      "Pair: 28/37\n",
      "Pair: 29/37\n",
      "Pair: 30/37\n",
      "Pair: 31/37\n",
      "Pair: 32/37\n",
      "Pair: 33/37\n",
      "Pair: 34/37\n",
      "Pair: 35/37\n",
      "Pair: 36/37\n",
      "Pair: 37/37\n"
     ]
    }
   ],
   "source": [
    "entry_multiplier= config['trading']['entry_multiplier']\n",
    "exit_multiplier= config['trading']['exit_multiplier']\n",
    "sharpe_results_kalman, cum_returns_kalman, performance_kalman = trader.apply_kalman_strategy(pairs, \n",
    "                                                                                             entry_multiplier,\n",
    "                                                                                             exit_multiplier,\n",
    "                                                                                             trading_filter,\n",
    "                                                                                             test_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average result:  3.4925561606627373\n",
      "avg_annual_roi:  66.64266083448007\n",
      "83.78378378378379 % of the pairs had positive returns\n"
     ]
    }
   ],
   "source": [
    "avg_sharpe_kalman, total_roi_kalman, anual_roi_kalman, positive_pct_kalman = \\\n",
    "    trader.calculate_metrics(sharpe_results_kalman, cum_returns_kalman, n_years_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average result:  3.4925561606627373\n",
      "avg_annual_roi:  66.64266083448007\n",
      "83.78378378378379 % of the pairs had positive returns\n"
     ]
    }
   ],
   "source": [
    "avg_sharpe_kalman, total_roi_kalman, anual_roi_kalman, positive_pct_kalman = \\\n",
    "    trader.calculate_metrics(sharpe_results_kalman, cum_returns_kalman, n_years_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio Distribution: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121e02ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Sharpe Ratio Distribution: ')\n",
    "n, bins, patches = plt.hist(sharpe_results_kalman, bins = 16, normed=True, orientation='vertical',\n",
    "                            color='red', rwidth=0.9, align='mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average result:  3.4925561606627373\n",
      "avg_annual_roi:  66.64266083448007\n",
      "83.78378378378379 % of the pairs had positive returns\n"
     ]
    }
   ],
   "source": [
    "results_training, pairs_summary_training = trader.summarize_results(sharpe_results_kalman, cum_returns_kalman,\n",
    "                                                  performance_kalman, pairs, ticker_segment_dict, n_years_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Leg1</th>\n",
       "      <th>Leg1_Segmt</th>\n",
       "      <th>Leg2</th>\n",
       "      <th>Leg2_Segmt</th>\n",
       "      <th>t_statistic</th>\n",
       "      <th>p_value</th>\n",
       "      <th>zero_cross</th>\n",
       "      <th>half_life</th>\n",
       "      <th>hurst_exponent</th>\n",
       "      <th>positive_trades</th>\n",
       "      <th>negative_trades</th>\n",
       "      <th>sharpe_result</th>\n",
       "      <th>positive_trades_per_pair_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FUD</td>\n",
       "      <td>Commodities: Agriculture</td>\n",
       "      <td>GRU</td>\n",
       "      <td>Commodities: Agriculture Grains</td>\n",
       "      <td>-3.462353</td>\n",
       "      <td>0.009008</td>\n",
       "      <td>81</td>\n",
       "      <td>42</td>\n",
       "      <td>0.366386</td>\n",
       "      <td>739</td>\n",
       "      <td>189</td>\n",
       "      <td>11.2399</td>\n",
       "      <td>79.633621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Leg1                Leg1_Segmt Leg2                       Leg2_Segmt  \\\n",
       "0  FUD  Commodities: Agriculture  GRU  Commodities: Agriculture Grains   \n",
       "\n",
       "   t_statistic   p_value  zero_cross  half_life  hurst_exponent  \\\n",
       "0    -3.462353  0.009008          81         42        0.366386   \n",
       "\n",
       "   positive_trades  negative_trades  sharpe_result  \\\n",
       "0              739              189        11.2399   \n",
       "\n",
       "   positive_trades_per_pair_pct  \n",
       "0                     79.633621  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_summary_training.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-6f4aad436a66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperformance_kalman\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m38\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperformance_kalman\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m38\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_position\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperformance_kalman\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m38\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperformance_kalman\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m38\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperformance_kalman\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m38\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mret\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperformance_kalman\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m38\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperformance_kalman\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m38\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mperformance_kalman\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m38\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperformance_kalman\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m38\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(len(performance_kalman[38][1][performance_kalman[38][1].current_position!=0])/len(performance_kalman[38][1]))\n",
    "print(len(performance_kalman[38][1][performance_kalman[38][1].ret < 0])/len(performance_kalman[38][1][performance_kalman[38][1].ret != 0]))\n",
    "performance_kalman[38][1][performance_kalman[38][1].ret != 0].ret.hist(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some remarks\n",
    "\n",
    "- From the analysis above, the Kalman filter method obtains the best performance, with an average Sharpe Ratio larger than 1.\n",
    "- We should compare this approach with a *compare all against all* approach, to see by which factor our results are improved due to the clustering technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out of Sample Analysis\n",
    "\n",
    "In this section, we analyze the performance of the strategy in the validation dataset. \n",
    "\n",
    "We proceed with some data exploration analysis. For this purpose we will do the following:\n",
    "\n",
    "- Analyze which percentage of the identified pairs are still cointegrated in the validation period.\n",
    "- Analyze which percentage of pairs have positive returns, and how many of those are still cointegrated.\n",
    "- Analyze how many new pais were not identified to be cointegrated up to the validation period.\n",
    "- Run strategy for identified pairs in training period.\n",
    "\n",
    "This analysis will help us getting some insight into how the cointegrated pairs vary from time to time, and therefore how we should allocate our resources to predict when pairs are not cointegrated anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the Strategy out-of Sample\n",
    "\n",
    "We might want to apply the strategy in all pairs identified. Or, instead, we might prefer to apply the strategy only on those pairs that turned out to be profitable. Let's compare how both approaches work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intraday\n",
    "n_years_test = round(len(df_prices_test)/(240*78))\n",
    "\n",
    "# interday\n",
    "n_years_test = round(len(df_prices_test)/(240))\n",
    "\n",
    "n_years_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1: Keeping every pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bollinger Bands Out-of-Sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1/37\n",
      "\n",
      "2/37\n",
      "\n",
      "3/37\n",
      "\n",
      "4/37\n",
      "\n",
      "5/37\n",
      "\n",
      "6/37\n",
      "\n",
      "7/37\n",
      "\n",
      "8/37\n",
      "\n",
      "9/37\n",
      "\n",
      "10/37\n",
      "\n",
      "11/37\n",
      "\n",
      "12/37\n",
      "\n",
      "13/37\n",
      "\n",
      "14/37\n",
      "\n",
      "15/37\n",
      "\n",
      "16/37\n",
      "\n",
      "17/37\n",
      "\n",
      "18/37\n",
      "\n",
      "19/37\n",
      "\n",
      "20/37\n",
      "\n",
      "21/37\n",
      "\n",
      "22/37\n",
      "\n",
      "23/37\n",
      "\n",
      "24/37\n",
      "\n",
      "25/37\n",
      "\n",
      "26/37\n",
      "\n",
      "27/37\n",
      "\n",
      "28/37\n",
      "\n",
      "29/37\n",
      "\n",
      "30/37\n",
      "\n",
      "31/37\n",
      "\n",
      "32/37\n",
      "\n",
      "33/37\n",
      "\n",
      "34/37\n",
      "\n",
      "35/37\n",
      "\n",
      "36/37\n",
      "\n",
      "37/37\n"
     ]
    }
   ],
   "source": [
    "sharpe_results_bollinger_test, cum_returns_bollinger_test, performance_bollinger_test =\\\n",
    "                                    trader.apply_bollinger_strategy(pairs,\n",
    "                                                                    lookback_multiplier,\n",
    "                                                                    entry_multiplier,\n",
    "                                                                    exit_multiplier,\n",
    "                                                                    trading_filter,\n",
    "                                                                    test_mode = True\n",
    "                                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average result:  0.29890132893089044\n",
      "avg_annual_roi:  5.212626241404594\n",
      "62.16216216216216 % of the pairs had positive returns\n"
     ]
    }
   ],
   "source": [
    "avg_sharpe_bollinger_test, total_roi_bollinger_test, anual_roi_bollinger_test, positive_pct_bollinger_test = \\\n",
    "    trader.calculate_metrics(sharpe_results_bollinger_test, cum_returns_bollinger_test, n_years_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kalman Out-of-Sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair: 1/37\n",
      "Pair: 2/37\n",
      "Pair: 3/37\n",
      "Pair: 4/37\n",
      "Pair: 5/37\n",
      "Pair: 6/37\n",
      "Pair: 7/37\n",
      "Pair: 8/37\n",
      "Pair: 9/37\n",
      "Pair: 10/37\n",
      "Pair: 11/37\n",
      "Pair: 12/37\n",
      "Pair: 13/37\n",
      "Pair: 14/37\n",
      "Pair: 15/37\n",
      "Pair: 16/37\n",
      "Pair: 17/37\n",
      "Pair: 18/37\n",
      "Pair: 19/37\n",
      "Pair: 20/37\n",
      "Pair: 21/37\n",
      "Pair: 22/37\n",
      "Pair: 23/37\n",
      "Pair: 24/37\n",
      "Pair: 25/37\n",
      "Pair: 26/37\n",
      "Pair: 27/37\n",
      "Pair: 28/37\n",
      "Pair: 29/37\n",
      "Pair: 30/37\n",
      "Pair: 31/37\n",
      "Pair: 32/37\n",
      "Pair: 33/37\n",
      "Pair: 34/37\n",
      "Pair: 35/37\n",
      "Pair: 36/37\n",
      "Pair: 37/37\n"
     ]
    }
   ],
   "source": [
    "sharpe_results_kalman_test, cum_returns_kalman_test, performance_kalman_test = trader.apply_kalman_strategy(pairs, \n",
    "                                                                                             entry_multiplier,\n",
    "                                                                                             exit_multiplier,\n",
    "                                                                                             trading_filter,\n",
    "                                                                                             test_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average result:  1.2334216864284595\n",
      "avg_annual_roi:  19.701964864998644\n",
      "86.11111111111111 % of the pairs had positive returns\n"
     ]
    }
   ],
   "source": [
    "avg_sharpe_kalman_test, total_roi_kalman_test, anual_roi_kalman_test, positive_pct_kalman_test = \\\n",
    "        trader.calculate_metrics(sharpe_results_kalman_test, cum_returns_kalman_test, n_years_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average result:  1.2334216864284595\n",
      "avg_annual_roi:  19.701964864998644\n",
      "86.11111111111111 % of the pairs had positive returns\n"
     ]
    }
   ],
   "source": [
    "avg_sharpe_kalman_test, total_roi_kalman_test, anual_roi_kalman_test, positive_pct_kalman_test = \\\n",
    "        trader.calculate_metrics(sharpe_results_kalman_test, cum_returns_kalman_test, n_years_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: Keeping only pairs that had positive returns in the training period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bollinger Strategy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpe_results_bollinger = np.asarray(sharpe_results_bollinger)\n",
    "profitable_pairs_indices = np.argwhere(sharpe_results_bollinger > 0)\n",
    "profitable_pairs = [pairs[i] for i in profitable_pairs_indices.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1/22\n",
      "\n",
      "2/22\n",
      "\n",
      "3/22\n",
      "\n",
      "4/22\n",
      "\n",
      "5/22\n",
      "\n",
      "6/22\n",
      "\n",
      "7/22\n",
      "\n",
      "8/22\n",
      "\n",
      "9/22\n",
      "\n",
      "10/22\n",
      "\n",
      "11/22\n",
      "\n",
      "12/22\n",
      "\n",
      "13/22\n",
      "\n",
      "14/22\n",
      "\n",
      "15/22\n",
      "\n",
      "16/22\n",
      "\n",
      "17/22\n",
      "\n",
      "18/22\n",
      "\n",
      "19/22\n",
      "\n",
      "20/22\n",
      "\n",
      "21/22\n",
      "\n",
      "22/22\n"
     ]
    }
   ],
   "source": [
    "sharpe_results_bollinger_test, cum_returns_bollinger_test, performance_bollinger_test =\\\n",
    "                                    trader.apply_bollinger_strategy(profitable_pairs,\n",
    "                                                                    lookback_multiplier,\n",
    "                                                                    entry_multiplier,\n",
    "                                                                    exit_multiplier,\n",
    "                                                                    trading_filter,\n",
    "                                                                    test_mode = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average result:  0.1592554962999629\n",
      "avg_annual_roi:  3.128326000952608\n",
      "54.54545454545455 % of the pairs had positive returns\n"
     ]
    }
   ],
   "source": [
    "avg_sharpe_bollinger_test, total_roi_bollinger_test, anual_roi_bollinger_test, positive_pct_bollinger_test = \\\n",
    "    trader.calculate_metrics(sharpe_results_bollinger_test, cum_returns_bollinger_test, n_years_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kalman Strategy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpe_results_kalman = np.asarray(sharpe_results_kalman)\n",
    "profitable_pairs_indices = np.argwhere(sharpe_results_kalman > 0)\n",
    "profitable_pairs = [pairs[i] for i in profitable_pairs_indices.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair: 1/31\n",
      "Pair: 2/31\n",
      "Pair: 3/31\n",
      "Pair: 4/31\n",
      "Pair: 5/31\n",
      "Pair: 6/31\n",
      "Pair: 7/31\n",
      "Pair: 8/31\n",
      "Pair: 9/31\n",
      "Pair: 10/31\n",
      "Pair: 11/31\n",
      "Pair: 12/31\n",
      "Pair: 13/31\n",
      "Pair: 14/31\n",
      "Pair: 15/31\n",
      "Pair: 16/31\n",
      "Pair: 17/31\n",
      "Pair: 18/31\n",
      "Pair: 19/31\n",
      "Pair: 20/31\n",
      "Pair: 21/31\n",
      "Pair: 22/31\n",
      "Pair: 23/31\n",
      "Pair: 24/31\n",
      "Pair: 25/31\n",
      "Pair: 26/31\n",
      "Pair: 27/31\n",
      "Pair: 28/31\n",
      "Pair: 29/31\n",
      "Pair: 30/31\n",
      "Pair: 31/31\n"
     ]
    }
   ],
   "source": [
    "sharpe_results_kalman_test, cum_returns_kalman_test, performance_kalman_test = trader.apply_kalman_strategy(\\\n",
    "                                                                                             profitable_pairs, \n",
    "                                                                                             entry_multiplier,\n",
    "                                                                                             exit_multiplier,\n",
    "                                                                                             trading_filter,\n",
    "                                                                                             test_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average result:  1.4097107012492123\n",
      "avg_annual_roi:  22.882000653908108\n",
      "96.66666666666667 % of the pairs had positive returns\n"
     ]
    }
   ],
   "source": [
    "avg_sharpe_kalman_test, total_roi_kalman_test, anual_roi_kalman_test, positive_pct_kalman_test = \\\n",
    "    trader.calculate_metrics(sharpe_results_kalman_test, cum_returns_kalman_test, n_years_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average result:  1.4097107012492123\n",
      "avg_annual_roi:  22.882000653908108\n",
      "96.66666666666667 % of the pairs had positive returns\n"
     ]
    }
   ],
   "source": [
    "# with entry multiplier = 2\n",
    "avg_sharpe_kalman_test, total_roi_kalman_test, anual_roi_kalman_test, positive_pct_kalman_test = \\\n",
    "    trader.calculate_metrics(sharpe_results_kalman_test, cum_returns_kalman_test, n_years_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude that the 2nd approach presents better results. From now on, we assume the 2nd approach was taken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate the results\n",
    "\n",
    "The results obtained are suspiciously high. We pretend to look deeper into the numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average result:  1.4097107012492123\n",
      "avg_annual_roi:  22.882000653908108\n",
      "96.66666666666667 % of the pairs had positive returns\n"
     ]
    }
   ],
   "source": [
    "with open(config['dataset']['ticker_segment_dict'], 'rb') as handle:\n",
    "    ticker_segment_dict = pickle.load(handle)\n",
    "results, pairs_summary = trader.summarize_results(sharpe_results_kalman_test, cum_returns_kalman_test,\n",
    "                                                  performance_kalman_test, profitable_pairs, ticker_segment_dict,\n",
    "                                                  n_years_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Leg1</th>\n",
       "      <th>Leg1_Segmt</th>\n",
       "      <th>Leg2</th>\n",
       "      <th>Leg2_Segmt</th>\n",
       "      <th>t_statistic</th>\n",
       "      <th>p_value</th>\n",
       "      <th>zero_cross</th>\n",
       "      <th>half_life</th>\n",
       "      <th>hurst_exponent</th>\n",
       "      <th>positive_trades</th>\n",
       "      <th>negative_trades</th>\n",
       "      <th>sharpe_result</th>\n",
       "      <th>positive_trades_per_pair_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DZZ</td>\n",
       "      <td>Inverse Commodities: Precious Metals Gold</td>\n",
       "      <td>GLL</td>\n",
       "      <td>Inverse Commodities: Precious Metals Gold</td>\n",
       "      <td>-4.209984</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>1731</td>\n",
       "      <td>264</td>\n",
       "      <td>0.191601</td>\n",
       "      <td>2167</td>\n",
       "      <td>501</td>\n",
       "      <td>18.497743</td>\n",
       "      <td>81.221889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXE</td>\n",
       "      <td>Equity: U.S. Oil &amp; Gas Exploration &amp; Production</td>\n",
       "      <td>PXI</td>\n",
       "      <td>Equity: U.S. Energy</td>\n",
       "      <td>-3.254769</td>\n",
       "      <td>0.017025</td>\n",
       "      <td>1378</td>\n",
       "      <td>237</td>\n",
       "      <td>0.151762</td>\n",
       "      <td>491</td>\n",
       "      <td>89</td>\n",
       "      <td>11.506743</td>\n",
       "      <td>84.655172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PXI</td>\n",
       "      <td>Equity: U.S. Energy</td>\n",
       "      <td>VDE</td>\n",
       "      <td>Equity: U.S. Energy</td>\n",
       "      <td>-3.067861</td>\n",
       "      <td>0.029025</td>\n",
       "      <td>1686</td>\n",
       "      <td>361</td>\n",
       "      <td>0.207953</td>\n",
       "      <td>640</td>\n",
       "      <td>167</td>\n",
       "      <td>9.961659</td>\n",
       "      <td>79.306072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DIG</td>\n",
       "      <td>Leveraged Equity: U.S. Energy</td>\n",
       "      <td>RYE</td>\n",
       "      <td>Equity: U.S. Energy</td>\n",
       "      <td>-2.928756</td>\n",
       "      <td>0.042105</td>\n",
       "      <td>2627</td>\n",
       "      <td>457</td>\n",
       "      <td>0.203705</td>\n",
       "      <td>279</td>\n",
       "      <td>59</td>\n",
       "      <td>9.098474</td>\n",
       "      <td>82.544379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IEO</td>\n",
       "      <td>Equity: U.S. Oil &amp; Gas Exploration &amp; Production</td>\n",
       "      <td>PXI</td>\n",
       "      <td>Equity: U.S. Energy</td>\n",
       "      <td>-3.433893</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>1569</td>\n",
       "      <td>488</td>\n",
       "      <td>0.241335</td>\n",
       "      <td>351</td>\n",
       "      <td>83</td>\n",
       "      <td>8.629540</td>\n",
       "      <td>80.875576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Leg1                                       Leg1_Segmt Leg2  \\\n",
       "0  DZZ        Inverse Commodities: Precious Metals Gold  GLL   \n",
       "1  PXE  Equity: U.S. Oil & Gas Exploration & Production  PXI   \n",
       "2  PXI                              Equity: U.S. Energy  VDE   \n",
       "3  DIG                    Leveraged Equity: U.S. Energy  RYE   \n",
       "4  IEO  Equity: U.S. Oil & Gas Exploration & Production  PXI   \n",
       "\n",
       "                                  Leg2_Segmt  t_statistic   p_value  \\\n",
       "0  Inverse Commodities: Precious Metals Gold    -4.209984  0.000634   \n",
       "1                        Equity: U.S. Energy    -3.254769  0.017025   \n",
       "2                        Equity: U.S. Energy    -3.067861  0.029025   \n",
       "3                        Equity: U.S. Energy    -2.928756  0.042105   \n",
       "4                        Equity: U.S. Energy    -3.433893  0.009856   \n",
       "\n",
       "   zero_cross  half_life  hurst_exponent  positive_trades  negative_trades  \\\n",
       "0        1731        264        0.191601             2167              501   \n",
       "1        1378        237        0.151762              491               89   \n",
       "2        1686        361        0.207953              640              167   \n",
       "3        2627        457        0.203705              279               59   \n",
       "4        1569        488        0.241335              351               83   \n",
       "\n",
       "   sharpe_result  positive_trades_per_pair_pct  \n",
       "0      18.497743                     81.221889  \n",
       "1      11.506743                     84.655172  \n",
       "2       9.961659                     79.306072  \n",
       "3       9.098474                     82.544379  \n",
       "4       8.629540                     80.875576  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_returns_adapted(Y, X, beta, positions):\n",
    "    \"\"\"\n",
    "    Y: price of ETF Y\n",
    "    X: price of ETF X\n",
    "    beta: cointegration ratio\n",
    "    \"\"\"\n",
    "    Y_returns = Y.pct_change().fillna(0)\n",
    "    X_returns = X.pct_change().fillna(0)\n",
    "    \n",
    "    returns = ((1/beta.shift(1))*Y_returns - 1*X_returns)*positions\n",
    "    cum_returns = np.cumprod(returns+1) - 1\n",
    "    \n",
    "    return returns, cum_returns\n",
    "\n",
    "#def calculate_returns_gatev2006(Y, X, beta, positions):\n",
    "#    \"\"\"\n",
    "#    Y: price of ETF Y\n",
    "#    X: price of ETF X\n",
    "#    beta: cointegration ratio\n",
    "#    \"\"\"\n",
    "#    Y_returns = np.cumprod(1 + Y.pct_change().fillna(0)) - 1\n",
    "#    X_returns = np.cumprod(1 + X.pct_change().fillna(0)) - 1\n",
    "#    \n",
    "#    pnl_Y = Y_returns*Y.pct_change().fillna(0)\n",
    "#    pnl_X = X_returns*X.pct_change().fillna(0)\n",
    "#    \n",
    "#    returns = (pnl_Y+pnl_X)/(Y_returns+X_returns)\n",
    "#    \n",
    "#    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapted_cum_ret_total = []\n",
    "for index in range(len(profitable_pairs)):\n",
    "    _, adapted_cum_ret = calculate_returns_adapted(\n",
    "                                        Y=performance_kalman_test[index][0][2]['Y_test'],\n",
    "                                        X=performance_kalman_test[index][0][2]['X_test'],\n",
    "                                        beta=performance_kalman_test[index][1]['beta'],\n",
    "                                        positions=performance_kalman_test[index][1]['current_position'])\n",
    "    adapted_cum_ret_total.append(adapted_cum_ret[-1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.71364602243183"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(adapted_cum_ret_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_ret_total = []\n",
    "for index in range(len(profitable_pairs)):\n",
    "    cum_ret = (np.cumprod(1 + performance_kalman_test[index][1].ret) - 1)[-1] * 100\n",
    "    cum_ret_total.append(cum_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.143871600556245"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cum_ret_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.890527439740545\n",
      "40.65076682039776\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "chan_ret = (np.cumprod(1 + performance_kalman_test[index][1].ret) - 1)[-1] * 100\n",
    "adapted_ret, adapted_cum_ret = calculate_returns_adapted(Y=performance_kalman_test[index][1]['FUD'],\n",
    "                                        X=performance_kalman_test[index][1]['GRU'],\n",
    "                                        beta=performance_kalman_test[index][1]['beta'],\n",
    "                                        positions=performance_kalman_test[index][1]['current_position'])\n",
    "print(chan_ret)\n",
    "print(adapted_cum_ret[-1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 3\n",
    "performance_bollinger_test[index][1]['2018-02-28':].head()#[performance_kalman_test[index][1].ret != 0]\n",
    "#(np.cumprod(1 + performance_bollinger_test[index][1].ret) - 1).iloc[-1] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ex = pd.Series(data=[5,4,3,2,1])\n",
    "Y_ex = pd.Series(data=[1,2,3,4,5])\n",
    "beta_ex = pd.Series(data=[1.1,1.2,1.3,1.4,1.5])\n",
    "positions_ex = pd.Series(data=[0,0,1,1,0])\n",
    "df_ex = pd.concat([X_ex, Y_ex, beta_ex, positions_ex], keys=['X_ex', 'Y_ex', 'beta', 'positions'],axis=1)\n",
    "df_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_returns_adapted(Y_ex, X_ex,beta_ex, positions_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Controlling for range of returns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Maximum return obtained in a single trade, per pair')\n",
    "for i in range(len(profitable_pairs)):\n",
    "    print(performance_kalman_test[i][1]['position_return_(%)'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Worst return obtained in a single trade, per pair')\n",
    "for i in range(len(profitable_pairs)):\n",
    "    print(performance_kalman_test[i][1]['position_return_(%)'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanto as returns m√°ximas como as m√≠nimas parecem ter valores dentro da normalidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training vs Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a far comparison, we should compare the test resuls with the results obtained in the training set, but also using only the profitable pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_multiplier= config['trading']['entry_multiplier']\n",
    "exit_multiplier= config['trading']['exit_multiplier']\n",
    "sharpe_results_kalman, cum_returns_kalman, performance_kalman = trader.apply_kalman_strategy(profitable_pairs, \n",
    "                                                                                             entry_multiplier,\n",
    "                                                                                             exit_multiplier,\n",
    "                                                                                             trading_filter,\n",
    "                                                                                             test_mode=False)\n",
    "avg_sharpe_kalman, total_roi_kalman, anual_roi_kalman, positive_pct_kalman = \\\n",
    "    trader.calculate_metrics(sharpe_results_kalman, cum_returns_kalman, n_years_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The sharpe ratio obtained in the training set with the pairs used on the test set is ', avg_sharpe_kalman)\n",
    "print('The sharpe ratio obtained in the test set is ', avg_sharpe_kalman_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the sharpe ratio is indeed higher in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(profitable_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Pairs' Overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There could be two possible interpretations for pairs' overlap.\n",
    "1. We might be interested in checking which of the cointegrated pairs found in the training dataset are also cointegrated in the test set; Furthermore we want to explore how the two types of pairs perform.\n",
    "2. We might be interested in finding if the pairs that would have been found in the test set by performing PCA + clustering would be cointegrated in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with **1)**, let's see how many of the identified pairs actually turned out to be cointegrated during this period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_overlapped, pairs_overlapped_index = series_analyser.pairs_overlap(pairs,\n",
    "                                  config['pair_restrictions']['p_value_threshold'],\n",
    "                                  config['pair_restrictions']['min_zero_crossings'],\n",
    "                                  config['pair_restrictions']['min_half_life'],\n",
    "                                  config['pair_restrictions']['hurst_threshold'])\n",
    "print('{} of the {} pairs identified in the training set are also cointegrated in the test set'.format(\\\n",
    "    len(pairs_overlapped), len(pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profitable_pairs_overlapped, profitable_pairs_overlapped_index = series_analyser.pairs_overlap(profitable_pairs,\n",
    "                                  config['pair_restrictions']['p_value_threshold'],\n",
    "                                  config['pair_restrictions']['min_zero_crossings'],\n",
    "                                  config['pair_restrictions']['min_half_life'],\n",
    "                                  config['pair_restrictions']['hurst_threshold'])\n",
    "print('{} of the {} pairs with positive returns identified in the training set are also cointegrated in the test set'.format(\\\n",
    "    len(profitable_pairs_overlapped), len(profitable_pairs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is cointegration really important?\n",
    "\n",
    "To answer this question we will see how many of the still cointegrated pairs had positive and negative returns. We will then do the same for those pairs that were not cointegrated. \n",
    "\n",
    "If both are as likely to have positive and negative returns, then it means cointegration is not as important of a condition. On the other hand, if we verify that all pairs that are still cointegrated turned out to be profitable and those that are not anymore led to consistent negative returns, we can infer that cointegration is a very important predictor of future returns.\n",
    "\n",
    "We also compare the average performance of the two groups two see the relevance of being cointegrated with respect to the sharpe ratio obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Still cointegrated*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution for pairs which were cointegrated in train and test\n",
    "sharpe_results_pairs_overlapped = np.asarray([sharpe_results_kalman_test[index] for index \\\n",
    "                                              in profitable_pairs_overlapped_index])\n",
    "cum_returns_pairs_overlapped = np.asarray([cum_returns_kalman_test[index] for index \\\n",
    "                                              in profitable_pairs_overlapped_index])\n",
    "\n",
    "if len(sharpe_results_pairs_overlapped)>0:\n",
    "    _,_,_,_ = trader.calculate_metrics(sharpe_results_pairs_overlapped, cum_returns_pairs_overlapped,\n",
    "                                   n_years_test)\n",
    "else:\n",
    "    print('0% of the pairs cointegrated in the train are also cointegrated in the test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Not cointegrated anymore*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution for pairs which were cointegrated in train but not in test\n",
    "profitable_pairs_not_overlapped_index = [i for i in np.arange(0,len(profitable_pairs))\\\n",
    "                                         if i not in profitable_pairs_overlapped_index]\n",
    "\n",
    "sharpe_results_pairs_not_overlapped = np.asarray([sharpe_results_kalman_test[index] for index \\\n",
    "                                              in profitable_pairs_not_overlapped_index])\n",
    "\n",
    "cum_returns_pairs_not_overlapped = np.asarray([cum_returns_kalman_test[index] for index \\\n",
    "                                              in profitable_pairs_not_overlapped_index])\n",
    "\n",
    "_,_,_,_ = trader.calculate_metrics(sharpe_results_pairs_not_overlapped, cum_returns_pairs_not_overlapped,\n",
    "                                   n_years_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answering to the first question we were concerned with, we verify that a cointegrated pair is indeed more likely to have a positive return. Furthermore, we can conclude from the results that being cointegrated implied that those pairs generated higher returns. \n",
    "\n",
    "**TO REVIEW:Conclusion**: The fact that a pair is not cointegrated anymore does not impact the results obained. In fact, we just concluded that betting solely on the cointegrated pairs would yield a worse result. Therefore, we should not spend much effort in detecting pairs that are no cointegrated anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following with point number **2)**, we proceed to analyze the performance of the pairs that woud have been identified in the testing period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_test_date = config['dataset']['testing_initial_date']\n",
    "final_teste_date = config['dataset']['testing_final_date']\n",
    "\n",
    "# Get returns for test period\n",
    "df_returns_test = data_processor.get_return_series(df_prices_test)\n",
    "\n",
    "# APPLY PCA and CLUSTERING\n",
    "range_n_components = config['PCA']['N_COMPONENTS']\n",
    "X_test, clustered_series_all_test, clustered_series_test, counts_test, clf_test = \\\n",
    "            series_analyser.clustering_for_optimal_PCA(range_n_components[0], range_n_components[1],\n",
    "                                                       df_returns_test, config['clustering'])\n",
    "# Find pairs\n",
    "pairs_test, unique_tickers_test = series_analyser.get_candidate_pairs(\\\n",
    "                                            clustered_series=clustered_series_test,\n",
    "                                            pricing_df_train=df_prices_test,\n",
    "                                            pricing_df_test=df_prices_train,\n",
    "                                            min_half_life=config['pair_restrictions']['min_half_life'],\n",
    "                                            min_zero_crosings=config['pair_restrictions']['min_zero_crossings'],\n",
    "                                            p_value_threshold=config['pair_restrictions']['p_value_threshold'],\n",
    "                                            hurst_threshold=config['pair_restrictions']['hurst_threshold']\n",
    "                                            )\n",
    "\n",
    "# Finally, see overlap\n",
    "pairs_overlapped, pairs_overlapped_index = series_analyser.pairs_overlap(pairs_test,\n",
    "                                  config['pair_restrictions']['p_value_threshold'],\n",
    "                                  config['pair_restrictions']['min_zero_crossings'],\n",
    "                                  config['pair_restrictions']['min_half_life'],\n",
    "                                  config['pair_restrictions']['hurst_threshold'])\n",
    "print('{} of the {} pairs identified in the test set are also cointegrated in the training set'.format(\\\n",
    "    len(pairs_overlapped), len(pairs_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the pairs identified in the test period lead indeed to improved results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sharpe_results_kalman_test_newpairs, cum_returns_kalman_test_newpairs, performance_kalman_test_newpairs =\\\n",
    "    trader.apply_kalman_strategy(pairs_test, entry_multiplier,exit_multiplier,trading_filter, test_mode=False)\n",
    "\n",
    "_,_,_,_ = trader.calculate_metrics(sharpe_results_kalman_test_newpairs, cum_returns_kalman_test_newpairs,\n",
    "                                   n_years_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sharpe ratio is higher in this scenatio. Note hoewever, that the annual ROI is not so high as the pairs identified previously. This might be linked with the fact that these pairs did not prove to be cointegrated for a period as long as the other and therefore the pairs might be less stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the influence of pairs statistics\n",
    "\n",
    "It's interesting to analyze whether we could have used extra information from the pairs trading statistic, instead of considering it just as a pass or not pass test. `Law 2017` explore this concept on their paper (htey basically rank pairs according to a trade off between t-statistic and spread deviation from its mean). However, what we see below is that there is no obvious influence of any parameter in the performance of the corresponding pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_summary.corr()[['sharpe_result', 'positive_trades_per_pair_pct']].loc[['t_statistic', 'p_value',\n",
    "                                                                             'zero_cross', 'half_life',\n",
    "                                                                             'hurst_exponent']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Correlation Filter\n",
    "\n",
    "The correlation filter aims to track how the correlation between the two legs of tha pair is varing, and provide that information as input to the trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_pair = failed_pairs[2]\n",
    "\n",
    "example_pair_leg1 = example_pair[0][0]\n",
    "example_pair_leg2 = example_pair[0][1]\n",
    "\n",
    "example_pair_prices = etfs_pricing[[example_pair_leg1, example_pair_leg2]]\n",
    "example_pair_prices.plot(figsize=(15,5))\n",
    "\n",
    "\n",
    "# proceed to calculate correlation\n",
    "rolling_window = config['trading']['lookback_multiplier']*example_pair[0][2]['half_life']\n",
    "\n",
    "# get returns\n",
    "example_pair_returns = data_processor.get_return_series(example_pair_prices)\n",
    "\n",
    "# analyze correlation on returns\n",
    "example_correlation = example_pair_returns[example_pair_leg1].rolling(rolling_window).corr(example_pair_returns[example_pair_leg2])\n",
    "\n",
    "# plot correlation of returns\n",
    "diff_example_correlation = example_correlation.diff(periods=1)\n",
    "#diff_example_correlation = diff_example_correlation*10\n",
    "diff_example_correlation.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result indicates there's almost no correlation between correlation diff and returns... Let's see how this result varies on average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_correlations = []\n",
    "for failure in failed_pairs:\n",
    "    failure_df = failure[1][failure[1].units != 0]\n",
    "    correlation = failure_df['ret'].corr(failure_df['correlation'])\n",
    "    failure_correlations.append(correlation)\n",
    "    \n",
    "print(np.mean(failure_correlations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we are not realyy interested in the correlation of the the diff column, but rather on the correlation with its sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_correlations = []\n",
    "for failure in failed_pairs:\n",
    "    failure_df = failure[1][failure[1].units != 0]\n",
    "    failure_df['diff_correlation_sign']=failure_df['diff_correlation'].apply(lambda row: -1 if row<0 else 1)\n",
    "    correlation = failure_df['ret'].corr(failure_df['diff_correlation_sign'])\n",
    "    failure_correlations.append(correlation)\n",
    "    \n",
    "print(np.mean(failure_correlations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use mutual information rather than correlation as the sign is discrete. What about the relation with the zscore evolution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze non-profitable pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpe_results_kalman_test = np.asarray(sharpe_results_kalman_test)\n",
    "negative_pairs_indices = np.argwhere(sharpe_results_kalman_test < 0)\n",
    "print('{} out of {} pairs turned out to be non-profitable'.format(len(negative_pairs_indices), len(pairs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some more information on the non-profitable pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_pairs = [pairs[i] for i in negative_pairs_indices.flatten()]\n",
    "negative_pairs = [(item[0], item[1]) for item in negative_pairs]\n",
    "negative_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To what clusters do these pairs belong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label_n in range(len(counts)):\n",
    "    elements_cluster_n = list(clustered_series[clustered_series == label_n].index)\n",
    "    etfs_cluster_n = etfs_unique[etfs_unique['Ticker'].isin(elements_cluster_n)]\n",
    "    for pair in negative_pairs:\n",
    "        if pair[0] in list(etfs_cluster_n.Ticker):\n",
    "            print('Pair {} belongs to cluster {}'.format(pair, label_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the statistics rank?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indices = np.flip(np.argsort(sharpe_results_bollinger), axis=0)\n",
    "\n",
    "# initialize list of lists \n",
    "data = []\n",
    "for index in sorted_indices:\n",
    "    # get number of positive and negative positions\n",
    "    position_returns = performance_bollinger[index][1].position_return\n",
    "    positive_positions = len(position_returns[position_returns>0])\n",
    "    negative_positions = len(position_returns[position_returns<0])\n",
    "    data.append([pairs[index][0],\n",
    "                 pairs[index][1],\n",
    "                 pairs[index][2]['t_statistic'],\n",
    "                 pairs[index][2]['p_value'],\n",
    "                 pairs[index][2]['zero_cross'],\n",
    "                 pairs[index][2]['half_life'],\n",
    "                 pairs[index][2]['hurst_exponent'],\n",
    "                 positive_positions,\n",
    "                 negative_positions,\n",
    "                 sharpe_results_bollinger[index]\n",
    "                ])\n",
    "      \n",
    "# Create the pandas DataFrame \n",
    "df = pd.DataFrame(data, columns = ['Leg1', 'Leg2', 't_statistic', 'p_value', 'zero_cross',\n",
    "                                   'half_life', 'hurst_exponent', 'positive trades', 'negative_trades',\n",
    "                                   'sharpe_result']) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.half_life.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze correlations\n",
    "print('Half-life vs Sharpe Ratio correlation: ', df['sharpe_result'].corr(df['half_life']))\n",
    "print('Zero crossings vs Sharpe Ratio correlation: ', df['sharpe_result'].corr(df['zero_cross']))\n",
    "print('p-value vs Sharpe Ratio correlation: ', df['sharpe_result'].corr(df['p_value']))\n",
    "print('t-statistic vs Sharpe Ratio correlation: ', df['sharpe_result'].corr(df['t_statistic']))\n",
    "print('Hurst exponent vs Sharpe Ratio correlation ', df['sharpe_result'].corr(df['hurst_exponent']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there any signs these pairs were not profitable as the strategy evolves? Could we have predicted their lack of profitability?\n",
    "- Using a ML algorithm that recognizes when a pair is not profitable anymore.\n",
    "- Checking how the hurst exponent has been changing.\n",
    "- Analyze their previous positions' returns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
